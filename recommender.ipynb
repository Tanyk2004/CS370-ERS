{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BkUgvTwc7l7O"
      },
      "source": [
        "## Educational Recommender System\n",
        "---\n",
        "\n",
        "Dataset: [Open University Learning Analytics dataset](https://analyse.kmi.open.ac.uk/open_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "zDCht_za7l7R"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
        "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
        "from sklearn.metrics import accuracy_score, mean_squared_error\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Q_58YldS7l7T"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cbgvv0NF8Zdu",
        "outputId": "423e6a4e-f91c-4a7f-888f-cc970092a311"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hDYW899D8bdz",
        "outputId": "c9990e5c-80bf-4670-8374-055f712f66a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "drive/MyDrive/\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "path = os.path.join(\"drive\", \"MyDrive\")\n",
        "path += \"/\"\n",
        "print(path)\n",
        "# path = \"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "BNLmHjkO7l7T"
      },
      "outputs": [],
      "source": [
        "# load csv files into dataframes\n",
        "assessments_df = pd.read_csv(path + 'data/assessments.csv')\n",
        "courses_df = pd.read_csv(path + 'data/courses.csv')\n",
        "student_assessment_df = pd.read_csv(path + 'data/studentAssessment.csv')\n",
        "student_info_df = pd.read_csv(path + 'data/studentInfo.csv')\n",
        "student_reg_df = pd.read_csv(path + 'data/studentRegistration.csv')\n",
        "student_vle_df = pd.read_csv(path + 'data/studentVle.csv')\n",
        "vle_df = pd.read_csv(path + 'data/vle.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ju0j8QEnFeNT",
        "outputId": "18d12d4d-874f-485b-e164-5f90184a222f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6364,)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "unique_vle_resources = vle_df['id_site'].unique()\n",
        "unique_vle_resources.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "NNb3K6ea7l7U"
      },
      "outputs": [],
      "source": [
        "# assessments_df, test_assessments_df = train_test_split(assessments_df, test_size=0.2, random_state=42)\n",
        "# courses_df, test_courses_df = train_test_split(courses_df, test_size=0.2, random_state=42)\n",
        "# student_assessment_df, test_student_assessment_df = train_test_split(student_assessment_df, test_size=0.2, random_state=42)\n",
        "# student_info_df, test_student_info_df = train_test_split(student_info_df, test_size=0.2, random_state=42)\n",
        "# student_reg_df, test_student_reg_df = train_test_split(student_reg_df, test_size=0.2, random_state=42)\n",
        "# student_vle_df, test_student_vle_df = train_test_split(student_vle_df, test_size=0.2, random_state=42)\n",
        "# vle_df, test_vle_df = train_test_split(vle_df, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BzSUdluiFeNU",
        "outputId": "6b746b6a-b240-48eb-e5d4-36fbc75dc687"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6268,)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "student_vle_df['id_site'].unique().shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "M3GqSvsz7l7V",
        "outputId": "b58414e3-c698-4ae1-9df8-5bb84e96ca32",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  code_module code_presentation  id_assessment assessment_type   date  weight\n",
              "0         AAA             2013J           1752             TMA   19.0    10.0\n",
              "1         AAA             2013J           1753             TMA   54.0    20.0\n",
              "2         AAA             2013J           1754             TMA  117.0    20.0\n",
              "3         AAA             2013J           1755             TMA  166.0    20.0\n",
              "4         AAA             2013J           1756             TMA  215.0    30.0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-143b34f9-4aac-4f12-ac51-6683b2af2624\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>code_module</th>\n",
              "      <th>code_presentation</th>\n",
              "      <th>id_assessment</th>\n",
              "      <th>assessment_type</th>\n",
              "      <th>date</th>\n",
              "      <th>weight</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>AAA</td>\n",
              "      <td>2013J</td>\n",
              "      <td>1752</td>\n",
              "      <td>TMA</td>\n",
              "      <td>19.0</td>\n",
              "      <td>10.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>AAA</td>\n",
              "      <td>2013J</td>\n",
              "      <td>1753</td>\n",
              "      <td>TMA</td>\n",
              "      <td>54.0</td>\n",
              "      <td>20.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>AAA</td>\n",
              "      <td>2013J</td>\n",
              "      <td>1754</td>\n",
              "      <td>TMA</td>\n",
              "      <td>117.0</td>\n",
              "      <td>20.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>AAA</td>\n",
              "      <td>2013J</td>\n",
              "      <td>1755</td>\n",
              "      <td>TMA</td>\n",
              "      <td>166.0</td>\n",
              "      <td>20.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>AAA</td>\n",
              "      <td>2013J</td>\n",
              "      <td>1756</td>\n",
              "      <td>TMA</td>\n",
              "      <td>215.0</td>\n",
              "      <td>30.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-143b34f9-4aac-4f12-ac51-6683b2af2624')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-143b34f9-4aac-4f12-ac51-6683b2af2624 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-143b34f9-4aac-4f12-ac51-6683b2af2624');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-f31c2b5f-ce03-4582-967c-274a98b0601f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f31c2b5f-ce03-4582-967c-274a98b0601f')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-f31c2b5f-ce03-4582-967c-274a98b0601f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "assessments_df",
              "summary": "{\n  \"name\": \"assessments_df\",\n  \"rows\": 206,\n  \"fields\": [\n    {\n      \"column\": \"code_module\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"AAA\",\n          \"BBB\",\n          \"FFF\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"code_presentation\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"2014J\",\n          \"2014B\",\n          \"2013J\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"id_assessment\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 10098,\n        \"min\": 1752,\n        \"max\": 40088,\n        \"num_unique_values\": 206,\n        \"samples\": [\n          14994,\n          1761,\n          37443\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"assessment_type\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"TMA\",\n          \"Exam\",\n          \"CMA\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"date\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 76.00111891714978,\n        \"min\": 12.0,\n        \"max\": 261.0,\n        \"num_unique_values\": 74,\n        \"samples\": [\n          215.0,\n          227.0,\n          110.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"weight\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 30.38422395904127,\n        \"min\": 0.0,\n        \"max\": 100.0,\n        \"num_unique_values\": 24,\n        \"samples\": [\n          35.0,\n          6.0,\n          10.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "assessments_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M18odsdn7l7W"
      },
      "source": [
        "### Removing Bias\n",
        "\n",
        "We need to remove certain columns in the student dataset so that recommendations out of our recommender system are not biased in any way.\n",
        "\n",
        "We will definitely be removing\n",
        "- Gender\n",
        "- Region\n",
        "\n",
        "We will be testing\n",
        "- Age\n",
        "- Economic Land\n",
        "- Previous Attempts\n",
        "- Disability\n",
        "- Number of Credits in the modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "NNXyhmXZ7l7W",
        "outputId": "7408e12f-046e-469d-ece8-4e3418203958",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  code_module code_presentation  id_student      highest_education imd_band  \\\n",
              "0         AAA             2013J       11391       HE Qualification  90-100%   \n",
              "1         AAA             2013J       28400       HE Qualification   20-30%   \n",
              "2         AAA             2013J       30268  A Level or Equivalent   30-40%   \n",
              "3         AAA             2013J       31604  A Level or Equivalent   50-60%   \n",
              "4         AAA             2013J       32885     Lower Than A Level   50-60%   \n",
              "\n",
              "  age_band  num_of_prev_attempts  studied_credits disability final_result  \n",
              "0     55<=                     0              240          N         Pass  \n",
              "1    35-55                     0               60          N         Pass  \n",
              "2    35-55                     0               60          Y    Withdrawn  \n",
              "3    35-55                     0               60          N         Pass  \n",
              "4     0-35                     0               60          N         Pass  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-38f59253-da46-436a-b7c6-a9077c3791dd\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>code_module</th>\n",
              "      <th>code_presentation</th>\n",
              "      <th>id_student</th>\n",
              "      <th>highest_education</th>\n",
              "      <th>imd_band</th>\n",
              "      <th>age_band</th>\n",
              "      <th>num_of_prev_attempts</th>\n",
              "      <th>studied_credits</th>\n",
              "      <th>disability</th>\n",
              "      <th>final_result</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>AAA</td>\n",
              "      <td>2013J</td>\n",
              "      <td>11391</td>\n",
              "      <td>HE Qualification</td>\n",
              "      <td>90-100%</td>\n",
              "      <td>55&lt;=</td>\n",
              "      <td>0</td>\n",
              "      <td>240</td>\n",
              "      <td>N</td>\n",
              "      <td>Pass</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>AAA</td>\n",
              "      <td>2013J</td>\n",
              "      <td>28400</td>\n",
              "      <td>HE Qualification</td>\n",
              "      <td>20-30%</td>\n",
              "      <td>35-55</td>\n",
              "      <td>0</td>\n",
              "      <td>60</td>\n",
              "      <td>N</td>\n",
              "      <td>Pass</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>AAA</td>\n",
              "      <td>2013J</td>\n",
              "      <td>30268</td>\n",
              "      <td>A Level or Equivalent</td>\n",
              "      <td>30-40%</td>\n",
              "      <td>35-55</td>\n",
              "      <td>0</td>\n",
              "      <td>60</td>\n",
              "      <td>Y</td>\n",
              "      <td>Withdrawn</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>AAA</td>\n",
              "      <td>2013J</td>\n",
              "      <td>31604</td>\n",
              "      <td>A Level or Equivalent</td>\n",
              "      <td>50-60%</td>\n",
              "      <td>35-55</td>\n",
              "      <td>0</td>\n",
              "      <td>60</td>\n",
              "      <td>N</td>\n",
              "      <td>Pass</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>AAA</td>\n",
              "      <td>2013J</td>\n",
              "      <td>32885</td>\n",
              "      <td>Lower Than A Level</td>\n",
              "      <td>50-60%</td>\n",
              "      <td>0-35</td>\n",
              "      <td>0</td>\n",
              "      <td>60</td>\n",
              "      <td>N</td>\n",
              "      <td>Pass</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-38f59253-da46-436a-b7c6-a9077c3791dd')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-38f59253-da46-436a-b7c6-a9077c3791dd button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-38f59253-da46-436a-b7c6-a9077c3791dd');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-7d787511-a30b-4f63-ae31-540866cee342\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7d787511-a30b-4f63-ae31-540866cee342')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-7d787511-a30b-4f63-ae31-540866cee342 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "student_info_df",
              "summary": "{\n  \"name\": \"student_info_df\",\n  \"rows\": 32593,\n  \"fields\": [\n    {\n      \"column\": \"code_module\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"AAA\",\n          \"BBB\",\n          \"FFF\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"code_presentation\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"2014J\",\n          \"2014B\",\n          \"2013J\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"id_student\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 549167,\n        \"min\": 3733,\n        \"max\": 2716795,\n        \"num_unique_values\": 28785,\n        \"samples\": [\n          582578,\n          524984,\n          606634\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"highest_education\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"A Level or Equivalent\",\n          \"No Formal quals\",\n          \"Lower Than A Level\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"imd_band\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"10-20\",\n          \"20-30%\",\n          \"70-80%\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"age_band\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"55<=\",\n          \"35-55\",\n          \"0-35\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"num_of_prev_attempts\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 6,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          0,\n          1,\n          5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"studied_credits\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 41,\n        \"min\": 30,\n        \"max\": 655,\n        \"num_unique_values\": 61,\n        \"samples\": [\n          240,\n          180,\n          175\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"disability\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Y\",\n          \"N\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"final_result\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"Withdrawn\",\n          \"Distinction\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "student_info_df.drop(inplace=True, columns=['gender', 'region'])\n",
        "student_info_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "oFX3qZhO7l7W"
      },
      "outputs": [],
      "source": [
        "# divide the courses into B and J categories based on \"code_presentation\" because the structure of these\n",
        "# presentations is different\n",
        "\n",
        "# student_vle_df = pd.merge(student_vle_df, vle_df, on='id_site')\n",
        "\n",
        "# * Pre processing Assessments\n",
        "courses_B_df = courses_df[courses_df['code_presentation'].str.contains('B')]\n",
        "courses_J_df = courses_df[courses_df['code_presentation'].str.contains('J')]\n",
        "\n",
        "# * Pre processing Assessments\n",
        "student_assessment_df = pd.merge(student_assessment_df, assessments_df, on='id_assessment')\n",
        "student_assessment_df = pd.get_dummies(student_assessment_df, columns=[\"assessment_type\", \"code_presentation\"])\n",
        "assessments_df.dropna(how='any', inplace=True)\n",
        "assessments_df = pd.get_dummies(assessments_df, columns=[\"assessment_type\"])\n",
        "assessments_df[\"date\"] = [int(date / 7) for date in assessments_df[\"date\"]]\n",
        "assessments_B_df = assessments_df[assessments_df['code_module'].isin(courses_B_df['code_module'])]\n",
        "assessments_J_df = assessments_df[assessments_df['code_module'].isin(courses_J_df['code_module'])]\n",
        "\n",
        "# * Pre processing VLE Dataset\n",
        "# ! This gets rid of the records with no week_from and week_to values\n",
        "# ! However, we are not sure if this is the right way to handle this\n",
        "# * Maybe we can use the student VLE interactions to fill in the missing values\n",
        "\n",
        "vle_df.drop(columns=['week_from', 'week_to'], inplace=True)\n",
        "vle_df = pd.get_dummies(vle_df, columns=[\"activity_type\"])\n",
        "vle_B_df = vle_df[vle_df['code_module'].isin(courses_B_df['code_module'])]\n",
        "vle_J_df = vle_df[vle_df['code_module'].isin(courses_J_df['code_module'])]\n",
        "\n",
        "\n",
        "# * Pre processing Student Info Dataset\n",
        "student_info_df.dropna(how='any', inplace=True)\n",
        "student_info_df = pd.get_dummies(student_info_df, columns=[\"highest_education\", \"imd_band\", \"age_band\", \"disability\", \"final_result\"])\n",
        "student_info_B_df = student_info_df[student_info_df['code_module'].isin(courses_B_df['code_module'])]\n",
        "student_info_J_df = student_info_df[student_info_df['code_module'].isin(courses_J_df['code_module'])]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "tcqeveDq7l7X"
      },
      "outputs": [],
      "source": [
        "def get_vle_interaction_by_site(id_site):\n",
        "    \"\"\"\n",
        "    Returns the student vle interaction for a given site id\n",
        "    \"\"\"\n",
        "    df = pd.DataFrame()\n",
        "    df = student_vle_df[student_vle_df['id_site'] == id_site]\n",
        "    return df\n",
        "\n",
        "def get_vle_interaction_by_student(student_id):\n",
        "    \"\"\"\n",
        "    Returns the student vle interaction for a given student id\n",
        "    \"\"\"\n",
        "    return student_vle_df[student_vle_df['id_student'] == student_id]\n",
        "\n",
        "def get_student_assessment_scores(student_id):\n",
        "    \"\"\"\n",
        "    Returns the student assessment scores for a given student id\n",
        "    \"\"\"\n",
        "    df = pd.DataFrame()\n",
        "    df = student_assessment_df[student_assessment_df['id_student'] == student_id]\n",
        "    return df\n",
        "\n",
        "def get_unique_vle_sites():\n",
        "    return student_vle_df['id_site'].unique()\n",
        "\n",
        "def calculate_euclidean_distance_student(student_id):\n",
        "    \"\"\"\n",
        "    Returns the euclidean distance between the student and all other students\n",
        "    \"\"\"\n",
        "    student = student_info_df[student_info_df['id_student'] == student_id]\n",
        "    student = student.drop(columns=['id_student'])\n",
        "    student = student.values\n",
        "    students = student_info_df.drop(columns=['id_student', 'code_module', 'code_presentation'])\n",
        "    students = students.values\n",
        "    return np.linalg.norm(students - student, axis=1)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "WWJ-dl8a7l7X",
        "outputId": "357514b6-676c-446f-b817-309bc535b3df",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(30757, 29)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "student_info_B_df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7yI6Poyx7l7X"
      },
      "source": [
        "### Data Exploration\n",
        "\n",
        "We need to find trends in students' engagement with the VLE and their test scores (indication of proficiency in a topic).It would appear that  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "fxs3KSSx7l7Y"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
        "# find a correlation between VLE Clicks and Student assesments\n",
        "\n",
        "def get_clicks_for_id_site_by_student(id_site, student_vle_interaction):\n",
        "    \"\"\"\n",
        "    Returns the number of clicks for a given site id\n",
        "    \"\"\"\n",
        "    return student_vle_interaction[student_vle_interaction['id_site'] == id_site].sum()[\"sum_click\"]\n",
        "\n",
        "def get_weighted_average_score(student_id):\n",
        "    \"\"\"\n",
        "    Returns the weighted average score for a given student\n",
        "    \"\"\"\n",
        "    assessment_scores = get_student_assessment_scores(student_id)\n",
        "    assessment_scores = pd.merge(assessment_scores, assessments_B_df, on='id_assessment')\n",
        "    average_score = 0\n",
        "    for index, row in assessment_scores.iterrows():\n",
        "        average_score += (row[\"weight_x\"] / 100) * row[\"score\"]\n",
        "    sum_assessment_weights = assessment_scores[\"weight_x\"].sum()\n",
        "    average_score = average_score / sum_assessment_weights\n",
        "    return average_score\n",
        "\n",
        "def corr_clicks_assessments():\n",
        "    \"\"\"\n",
        "    Displays the correlation between VLE Clicks and Student assesments\n",
        "\n",
        "    ! Caution: We are only analyzing the B presentations for now\n",
        "    \"\"\"\n",
        "    clicks_assessment_scores_df = pd.DataFrame()\n",
        "\n",
        "    SAMPLE_SIZE = 1000\n",
        "\n",
        "    for index, student in tqdm(student_info_B_df.sample(n=SAMPLE_SIZE).iterrows(), total=SAMPLE_SIZE, desc=\"Processing Students\"):\n",
        "        assessment_scores = get_student_assessment_scores(student[\"id_student\"])\n",
        "        student_vle_interaction = get_vle_interaction_by_student(student[\"id_student\"])\n",
        "\n",
        "        assessment_scores = pd.merge(assessment_scores, assessments_B_df, on='id_assessment')\n",
        "\n",
        "        sum_clicks_per_student = 0\n",
        "        for id_site in student_vle_interaction[\"id_site\"].unique():\n",
        "            clicks = get_clicks_for_id_site_by_student(id_site, student_vle_interaction)\n",
        "            sum_clicks_per_student += clicks\n",
        "\n",
        "        average_score = 0\n",
        "        for index, row in assessment_scores.iterrows():\n",
        "            average_score += (row[\"weight_x\"] / 100) * row[\"score\"]\n",
        "        sum_assessment_weights = assessment_scores[\"weight_x\"].sum()\n",
        "        average_score = average_score / sum_assessment_weights\n",
        "        new_row = pd.DataFrame({\"sum_clicks\": [sum_clicks_per_student], \"average_score\": [average_score]})\n",
        "        if (sum_clicks_per_student < 1500):\n",
        "            clicks_assessment_scores_df = pd.concat([clicks_assessment_scores_df, new_row], ignore_index=True)\n",
        "\n",
        "    # fit a least squares line\n",
        "    X = clicks_assessment_scores_df[\"sum_clicks\"].values.reshape(-1, 1)\n",
        "    y = clicks_assessment_scores_df[\"average_score\"].values.reshape(-1, 1)\n",
        "\n",
        "    # drop NaN values from y and drop the corresponding x values\n",
        "\n",
        "    nan_indices = np.isnan(y)\n",
        "\n",
        "    X = X[~nan_indices]\n",
        "    y = y[~nan_indices]\n",
        "\n",
        "    X = X.reshape(-1, 1)\n",
        "    y = y.reshape(-1, 1)\n",
        "\n",
        "    model = LinearRegression().fit(X, y)\n",
        "    m = model.coef_[0][0]\n",
        "    b = model.intercept_[0]\n",
        "\n",
        "    plt.scatter(clicks_assessment_scores_df[\"sum_clicks\"], clicks_assessment_scores_df[\"average_score\"])\n",
        "    plt.plot(X, m * X + b, color='red')\n",
        "    plt.xlabel(\"Sum Clicks\")\n",
        "    plt.ylabel(\"Average Score\")\n",
        "    plt.title(\"Correlation between Sum Clicks and Average Score\")\n",
        "    plt.show()\n",
        "\n",
        "    correlation_clicks_average_score = clicks_assessment_scores_df[\"sum_clicks\"].corr(clicks_assessment_scores_df[\"average_score\"])\n",
        "    print(f\"Correlation between Sum Clicks and Average Score: {correlation_clicks_average_score}\")\n",
        "\n",
        "\n",
        "\n",
        "# corr_clicks_assessments()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bFQcxO2G7l7Y"
      },
      "source": [
        "### Clicks vs Type of Content\n",
        "\n",
        "We needed to see if the sum_clicks differ drastically based on content type in the VLE. It would appear that it does. There seems to be steep difference in the sum_clicks on \"oucontent\" type vs something like \"dataplus\". OUContent appears to be content embedded within the Open University VLE itself and the abnormally large sum_clicks could be due to a tracking deficit in other activity types.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "Gs1hcSGr7l7Y"
      },
      "outputs": [],
      "source": [
        "# Get distribution of clicks by type of activity\n",
        "\n",
        "def show_clicks_by_type():\n",
        "    \"\"\"\n",
        "    Displays the distribution of clicks by type of activity\n",
        "    \"\"\"\n",
        "    global student_vle_df\n",
        "    merged_vle = pd.merge(student_vle_df, vle_df, on='id_site')\n",
        "    # print(merged_vle.head())\n",
        "    activity_names = merged_vle.columns[10:]\n",
        "    activity_names = pd.Series(activity_names)\n",
        "    for i in range(len(activity_names)):\n",
        "        activity_names[i] = activity_names[i].replace(\"activity_type_\", \"\")\n",
        "    clicks_by_type = np.zeros(shape=(len(activity_names), 1))\n",
        "\n",
        "    # Add clicks to clicks by type based on which activity column has True\n",
        "    activity_columns = merged_vle.columns[10:]\n",
        "    clicks_by_type = merged_vle[activity_columns].multiply(merged_vle[\"sum_click\"], axis=\"index\").sum(axis=0).values\n",
        "    clicks_by_type = pd.DataFrame(clicks_by_type, index=activity_names, columns=[\"sum_click\"])\n",
        "\n",
        "    clicks_by_type.plot(kind='bar')\n",
        "    plt.xlabel(\"Activity Type\")\n",
        "    plt.ylabel(\"Sum Clicks\")\n",
        "    plt.title(\"Distribution of Clicks by Type of Activity\")\n",
        "    plt.show()\n",
        "\n",
        "# show_clicks_by_type()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "cQF0WQJp7l7Y"
      },
      "outputs": [],
      "source": [
        "# Get how many of each resource is there\n",
        "def get_resource_distribution():\n",
        "    \"\"\"\n",
        "    Returns the distribution of resources\n",
        "    \"\"\"\n",
        "\n",
        "    global student_vle_df\n",
        "    # student_vle_df = pd.merge(student_vle_df, vle_df, on='id_site')\n",
        "    merged_vle = pd.merge(student_vle_df, vle_df, on='id_site')\n",
        "    activity_names = merged_vle.columns[10:]\n",
        "    activity_names = pd.Series(activity_names)\n",
        "    for i in range(len(activity_names)):\n",
        "        activity_names[i] = activity_names[i].replace(\"activity_type_\", \"\")\n",
        "\n",
        "    activity_vectors = np.array(merged_vle.iloc[:, 10:], dtype=np.float64)\n",
        "    clicks_by_type = activity_vectors.sum(axis=0)\n",
        "    clicks_by_type = pd.DataFrame(clicks_by_type, index=activity_names, columns=[\"sum_click\"])\n",
        "    clicks_by_type.plot(kind='bar')\n",
        "    plt.xlabel(\"Activity Type\")\n",
        "    plt.ylabel(\"Sum Clicks\")\n",
        "    plt.title(\"Distribution of Clicks by Type of Activity\")\n",
        "    plt.show()\n",
        "\n",
        "# get_resource_distribution()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "1nDNYrjv7l7Z"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "import datetime\n",
        "import numpy as np\n",
        "\n",
        "# Get sucessful student ids\n",
        "def get_student_assessment_trends_slope(student_info_dataframe):\n",
        "    \"\"\"\n",
        "    Returns the ids of successful students\n",
        "    Currently the heuristic is to find students with a positive slope in their assessment scores\n",
        "    The slope threshold currently is 0.05 because that is the 75th percentile of the slope distribution\n",
        "    \"\"\"\n",
        "    # plot student assessment trends\n",
        "    student_assessment_df_merged = pd.merge(student_assessment_df, assessments_df, on='id_assessment')\n",
        "    student_trend_df = pd.DataFrame()\n",
        "\n",
        "    for index, student in tqdm(student_info_dataframe.iterrows(), total=student_info_dataframe.shape[0], desc=\"Processing Students\"):\n",
        "        student_scores = get_student_assessment_scores(student[\"id_student\"])\n",
        "\n",
        "        if (student_scores.empty):\n",
        "            continue\n",
        "\n",
        "        student_scores = student_scores.dropna(how='any', inplace=False)\n",
        "\n",
        "        # calculate a linear regression line for the student scores\n",
        "        x = student_scores[\"date\"].values.reshape(-1, 1)\n",
        "        y = student_scores[\"score\"].values.reshape(-1, 1)\n",
        "        if x.size == 0 or y.size == 0:\n",
        "           continue\n",
        "        model = LinearRegression()\n",
        "        model.fit(x, y)\n",
        "        m = model.coef_[0][0]\n",
        "        b = model.intercept_[0]\n",
        "        if x.size > 4:\n",
        "            new_row = pd.DataFrame([{\"slope\": m, \"intercept\": b, \"id_student\": student[\"id_student\"]}])\n",
        "            student_trend_df = pd.concat([student_trend_df, new_row], ignore_index=True)\n",
        "\n",
        "    student_trend_df = pd.merge(student_trend_df, student_info_dataframe, on='id_student')\n",
        "    return student_trend_df\n",
        "\n",
        "def get_successful_student_trends(student_info_dataframe):\n",
        "    df = get_student_assessment_trends_slope(student_info_dataframe)\n",
        "    return df[df[\"slope\"] > df[\"slope\"].describe()[\"75%\"]]\n",
        "\n",
        "# get_successful_student_trends(student_info_B_df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "oAqwPhay7l7Z",
        "outputId": "bbc62f36-b2d2-45ad-81a2-4a4e11549ac5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Students: 100%|██████████| 50/50 [00:00<00:00, 398.92it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    id_student code_module code_presentation  num_of_prev_attempts  \\\n",
              "3       279085         FFF             2013J                     0   \n",
              "4      2680312         AAA             2014J                     0   \n",
              "29      515774         CCC             2014B                     0   \n",
              "9       565653         FFF             2013J                     0   \n",
              "8       557351         BBB             2013B                     0   \n",
              "\n",
              "    studied_credits  highest_education_A Level or Equivalent  \\\n",
              "3                60                                    False   \n",
              "4                60                                    False   \n",
              "29               60                                     True   \n",
              "9                90                                     True   \n",
              "8                90                                     True   \n",
              "\n",
              "    highest_education_HE Qualification  highest_education_Lower Than A Level  \\\n",
              "3                                 True                                 False   \n",
              "4                                 True                                 False   \n",
              "29                               False                                 False   \n",
              "9                                False                                 False   \n",
              "8                                False                                 False   \n",
              "\n",
              "    highest_education_No Formal quals  \\\n",
              "3                               False   \n",
              "4                               False   \n",
              "29                              False   \n",
              "9                               False   \n",
              "8                               False   \n",
              "\n",
              "    highest_education_Post Graduate Qualification  ...  imd_band_90-100%  \\\n",
              "3                                           False  ...             False   \n",
              "4                                           False  ...              True   \n",
              "29                                          False  ...             False   \n",
              "9                                           False  ...             False   \n",
              "8                                           False  ...             False   \n",
              "\n",
              "    age_band_0-35  age_band_35-55  age_band_55<=  disability_N  disability_Y  \\\n",
              "3           False            True          False          True         False   \n",
              "4           False           False           True          True         False   \n",
              "29          False            True          False          True         False   \n",
              "9            True           False          False          True         False   \n",
              "8            True           False          False          True         False   \n",
              "\n",
              "    final_result_Distinction  final_result_Fail  final_result_Pass  \\\n",
              "3                      False              False               True   \n",
              "4                      False              False               True   \n",
              "29                     False              False               True   \n",
              "9                      False              False              False   \n",
              "8                      False               True              False   \n",
              "\n",
              "    final_result_Withdrawn  \n",
              "3                    False  \n",
              "4                    False  \n",
              "29                   False  \n",
              "9                     True  \n",
              "8                    False  \n",
              "\n",
              "[5 rows x 29 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2421286d-29b5-4772-86cf-5a9fdf4030d9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id_student</th>\n",
              "      <th>code_module</th>\n",
              "      <th>code_presentation</th>\n",
              "      <th>num_of_prev_attempts</th>\n",
              "      <th>studied_credits</th>\n",
              "      <th>highest_education_A Level or Equivalent</th>\n",
              "      <th>highest_education_HE Qualification</th>\n",
              "      <th>highest_education_Lower Than A Level</th>\n",
              "      <th>highest_education_No Formal quals</th>\n",
              "      <th>highest_education_Post Graduate Qualification</th>\n",
              "      <th>...</th>\n",
              "      <th>imd_band_90-100%</th>\n",
              "      <th>age_band_0-35</th>\n",
              "      <th>age_band_35-55</th>\n",
              "      <th>age_band_55&lt;=</th>\n",
              "      <th>disability_N</th>\n",
              "      <th>disability_Y</th>\n",
              "      <th>final_result_Distinction</th>\n",
              "      <th>final_result_Fail</th>\n",
              "      <th>final_result_Pass</th>\n",
              "      <th>final_result_Withdrawn</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>279085</td>\n",
              "      <td>FFF</td>\n",
              "      <td>2013J</td>\n",
              "      <td>0</td>\n",
              "      <td>60</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2680312</td>\n",
              "      <td>AAA</td>\n",
              "      <td>2014J</td>\n",
              "      <td>0</td>\n",
              "      <td>60</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>515774</td>\n",
              "      <td>CCC</td>\n",
              "      <td>2014B</td>\n",
              "      <td>0</td>\n",
              "      <td>60</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>565653</td>\n",
              "      <td>FFF</td>\n",
              "      <td>2013J</td>\n",
              "      <td>0</td>\n",
              "      <td>90</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>557351</td>\n",
              "      <td>BBB</td>\n",
              "      <td>2013B</td>\n",
              "      <td>0</td>\n",
              "      <td>90</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 29 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2421286d-29b5-4772-86cf-5a9fdf4030d9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2421286d-29b5-4772-86cf-5a9fdf4030d9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2421286d-29b5-4772-86cf-5a9fdf4030d9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-f0c3f46c-2ed1-41c1-9f8f-103ee3b59906\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f0c3f46c-2ed1-41c1-9f8f-103ee3b59906')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-f0c3f46c-2ed1-41c1-9f8f-103ee3b59906 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "def knn_recommender(id_student, selective_student_info_dataframe, k=5):\n",
        "    \"\"\"\n",
        "    ### Parameters\n",
        "        - id_student: The student id for which we want to find similar students\n",
        "        - selective_student_info_dataframe: The dataframe containing 'successful' students\n",
        "\n",
        "    ### Returns\n",
        "        Returns the top k similar students to the given student id\n",
        "    \"\"\"\n",
        "    student = student_info_df[student_info_df['id_student'] == id_student]\n",
        "    student = student.drop(columns=['id_student', 'code_module', 'code_presentation'])\n",
        "    student = student.iloc[0]\n",
        "    students = selective_student_info_dataframe.drop(columns=['id_student', 'code_module', 'code_presentation'])\n",
        "    student = np.array(student, dtype=float)\n",
        "    students = np.array(students, dtype=float)\n",
        "    distances = np.linalg.norm(students - student, axis=1)\n",
        "    indices = np.argsort(distances)[:k]\n",
        "    return selective_student_info_dataframe.iloc[indices]\n",
        "\n",
        "successful_students = get_successful_student_trends(student_info_df.sample(n=50))\n",
        "successful_students.drop(columns=['slope', 'intercept'], inplace=True)\n",
        "knn_recommender(student_info_df.sample(n=1).iloc[0][\"id_student\"], successful_students, k=5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "0C9WsXj07l7Z",
        "outputId": "0c2939dd-9733-4e6d-b5c0-6f476e0f142e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         code_module_x code_presentation_x  id_student  id_site  date  \\\n",
              "0                  AAA               2013J       28400   546652   -10   \n",
              "1                  AAA               2013J       28400   546652   -10   \n",
              "2                  AAA               2013J       28400   546652   -10   \n",
              "3                  AAA               2013J       28400   546614   -10   \n",
              "4                  AAA               2013J       28400   546714   -10   \n",
              "...                ...                 ...         ...      ...   ...   \n",
              "10655275           GGG               2014J      675811   896943   269   \n",
              "10655276           GGG               2014J      675578   896943   269   \n",
              "10655277           GGG               2014J      654064   896943   269   \n",
              "10655278           GGG               2014J      654064   896939   269   \n",
              "10655279           GGG               2014J      654064   896939   269   \n",
              "\n",
              "          sum_click code_module_y code_presentation_y  activity_type_dataplus  \\\n",
              "0                 4           AAA               2013J                   False   \n",
              "1                 1           AAA               2013J                   False   \n",
              "2                 1           AAA               2013J                   False   \n",
              "3                11           AAA               2013J                   False   \n",
              "4                 1           AAA               2013J                   False   \n",
              "...             ...           ...                 ...                     ...   \n",
              "10655275          3           GGG               2014J                   False   \n",
              "10655276          1           GGG               2014J                   False   \n",
              "10655277          3           GGG               2014J                   False   \n",
              "10655278          1           GGG               2014J                   False   \n",
              "10655279          1           GGG               2014J                   False   \n",
              "\n",
              "          activity_type_dualpane  ...  activity_type_ouelluminate  \\\n",
              "0                          False  ...                       False   \n",
              "1                          False  ...                       False   \n",
              "2                          False  ...                       False   \n",
              "3                          False  ...                       False   \n",
              "4                          False  ...                       False   \n",
              "...                          ...  ...                         ...   \n",
              "10655275                   False  ...                       False   \n",
              "10655276                   False  ...                       False   \n",
              "10655277                   False  ...                       False   \n",
              "10655278                   False  ...                       False   \n",
              "10655279                   False  ...                       False   \n",
              "\n",
              "          activity_type_ouwiki  activity_type_page  \\\n",
              "0                        False               False   \n",
              "1                        False               False   \n",
              "2                        False               False   \n",
              "3                        False               False   \n",
              "4                        False               False   \n",
              "...                        ...                 ...   \n",
              "10655275                 False               False   \n",
              "10655276                 False               False   \n",
              "10655277                 False               False   \n",
              "10655278                 False               False   \n",
              "10655279                 False               False   \n",
              "\n",
              "          activity_type_questionnaire  activity_type_quiz  \\\n",
              "0                               False               False   \n",
              "1                               False               False   \n",
              "2                               False               False   \n",
              "3                               False               False   \n",
              "4                               False               False   \n",
              "...                               ...                 ...   \n",
              "10655275                        False               False   \n",
              "10655276                        False               False   \n",
              "10655277                        False               False   \n",
              "10655278                        False               False   \n",
              "10655279                        False               False   \n",
              "\n",
              "          activity_type_repeatactivity  activity_type_resource  \\\n",
              "0                                False                   False   \n",
              "1                                False                   False   \n",
              "2                                False                   False   \n",
              "3                                False                   False   \n",
              "4                                False                   False   \n",
              "...                                ...                     ...   \n",
              "10655275                         False                   False   \n",
              "10655276                         False                   False   \n",
              "10655277                         False                   False   \n",
              "10655278                         False                   False   \n",
              "10655279                         False                   False   \n",
              "\n",
              "          activity_type_sharedsubpage  activity_type_subpage  \\\n",
              "0                               False                  False   \n",
              "1                               False                  False   \n",
              "2                               False                  False   \n",
              "3                               False                  False   \n",
              "4                               False                  False   \n",
              "...                               ...                    ...   \n",
              "10655275                        False                  False   \n",
              "10655276                        False                  False   \n",
              "10655277                        False                  False   \n",
              "10655278                        False                  False   \n",
              "10655279                        False                  False   \n",
              "\n",
              "          activity_type_url  \n",
              "0                     False  \n",
              "1                     False  \n",
              "2                     False  \n",
              "3                     False  \n",
              "4                     False  \n",
              "...                     ...  \n",
              "10655275              False  \n",
              "10655276              False  \n",
              "10655277              False  \n",
              "10655278              False  \n",
              "10655279              False  \n",
              "\n",
              "[10655280 rows x 28 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b13f161c-3067-4092-b963-b17bea0bd730\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>code_module_x</th>\n",
              "      <th>code_presentation_x</th>\n",
              "      <th>id_student</th>\n",
              "      <th>id_site</th>\n",
              "      <th>date</th>\n",
              "      <th>sum_click</th>\n",
              "      <th>code_module_y</th>\n",
              "      <th>code_presentation_y</th>\n",
              "      <th>activity_type_dataplus</th>\n",
              "      <th>activity_type_dualpane</th>\n",
              "      <th>...</th>\n",
              "      <th>activity_type_ouelluminate</th>\n",
              "      <th>activity_type_ouwiki</th>\n",
              "      <th>activity_type_page</th>\n",
              "      <th>activity_type_questionnaire</th>\n",
              "      <th>activity_type_quiz</th>\n",
              "      <th>activity_type_repeatactivity</th>\n",
              "      <th>activity_type_resource</th>\n",
              "      <th>activity_type_sharedsubpage</th>\n",
              "      <th>activity_type_subpage</th>\n",
              "      <th>activity_type_url</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>AAA</td>\n",
              "      <td>2013J</td>\n",
              "      <td>28400</td>\n",
              "      <td>546652</td>\n",
              "      <td>-10</td>\n",
              "      <td>4</td>\n",
              "      <td>AAA</td>\n",
              "      <td>2013J</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>AAA</td>\n",
              "      <td>2013J</td>\n",
              "      <td>28400</td>\n",
              "      <td>546652</td>\n",
              "      <td>-10</td>\n",
              "      <td>1</td>\n",
              "      <td>AAA</td>\n",
              "      <td>2013J</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>AAA</td>\n",
              "      <td>2013J</td>\n",
              "      <td>28400</td>\n",
              "      <td>546652</td>\n",
              "      <td>-10</td>\n",
              "      <td>1</td>\n",
              "      <td>AAA</td>\n",
              "      <td>2013J</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>AAA</td>\n",
              "      <td>2013J</td>\n",
              "      <td>28400</td>\n",
              "      <td>546614</td>\n",
              "      <td>-10</td>\n",
              "      <td>11</td>\n",
              "      <td>AAA</td>\n",
              "      <td>2013J</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>AAA</td>\n",
              "      <td>2013J</td>\n",
              "      <td>28400</td>\n",
              "      <td>546714</td>\n",
              "      <td>-10</td>\n",
              "      <td>1</td>\n",
              "      <td>AAA</td>\n",
              "      <td>2013J</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10655275</th>\n",
              "      <td>GGG</td>\n",
              "      <td>2014J</td>\n",
              "      <td>675811</td>\n",
              "      <td>896943</td>\n",
              "      <td>269</td>\n",
              "      <td>3</td>\n",
              "      <td>GGG</td>\n",
              "      <td>2014J</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10655276</th>\n",
              "      <td>GGG</td>\n",
              "      <td>2014J</td>\n",
              "      <td>675578</td>\n",
              "      <td>896943</td>\n",
              "      <td>269</td>\n",
              "      <td>1</td>\n",
              "      <td>GGG</td>\n",
              "      <td>2014J</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10655277</th>\n",
              "      <td>GGG</td>\n",
              "      <td>2014J</td>\n",
              "      <td>654064</td>\n",
              "      <td>896943</td>\n",
              "      <td>269</td>\n",
              "      <td>3</td>\n",
              "      <td>GGG</td>\n",
              "      <td>2014J</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10655278</th>\n",
              "      <td>GGG</td>\n",
              "      <td>2014J</td>\n",
              "      <td>654064</td>\n",
              "      <td>896939</td>\n",
              "      <td>269</td>\n",
              "      <td>1</td>\n",
              "      <td>GGG</td>\n",
              "      <td>2014J</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10655279</th>\n",
              "      <td>GGG</td>\n",
              "      <td>2014J</td>\n",
              "      <td>654064</td>\n",
              "      <td>896939</td>\n",
              "      <td>269</td>\n",
              "      <td>1</td>\n",
              "      <td>GGG</td>\n",
              "      <td>2014J</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10655280 rows × 28 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b13f161c-3067-4092-b963-b17bea0bd730')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b13f161c-3067-4092-b963-b17bea0bd730 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b13f161c-3067-4092-b963-b17bea0bd730');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-f3045bf4-4c67-4c8f-9a18-bb365cdf0cc4\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f3045bf4-4c67-4c8f-9a18-bb365cdf0cc4')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-f3045bf4-4c67-4c8f-9a18-bb365cdf0cc4 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "def prepare_DTree_data(student_features_df, resource_features_df, student_assessment_df):\n",
        "    \"\"\"\n",
        "    Prepares the data for the Decision Tree\n",
        "\n",
        "    We want to merge student features with resource features and then our target variable is the assessment score\n",
        "    \"\"\"\n",
        "\n",
        "    # merge the student features with the resource features\n",
        "    merged_df = pd.merge(student_features_df, resource_features_df, on='id_site')\n",
        "\n",
        "    return merged_df\n",
        "\n",
        "prepare_DTree_data(student_vle_df, vle_df, student_assessment_df)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0pD5iTMv7l7a"
      },
      "source": [
        "### Association Analysis\n",
        "\n",
        "We want to treat the resources a student consumes as items in the itemsets.\n",
        "\n",
        "TODO:\n",
        "- Create Itemsets from the resources students have consumed.\n",
        "- Append relevant information to the itemsets that indicate the impact of the itemset (average [weighted] grade or grade for the assessment that those resources were used before)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "TnoPvgkG7l7b",
        "outputId": "e526bb05-57a8-436e-e381-8552316a0b35",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Students: 100%|██████████| 10/10 [00:00<00:00, 133.78it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[773425,\n",
              "  773080,\n",
              "  773459,\n",
              "  772705,\n",
              "  773452,\n",
              "  773202,\n",
              "  773122,\n",
              "  773390,\n",
              "  773141,\n",
              "  773144,\n",
              "  772735,\n",
              "  773161,\n",
              "  773182,\n",
              "  773364,\n",
              "  773340,\n",
              "  773259,\n",
              "  773034,\n",
              "  772990,\n",
              "  772987,\n",
              "  773001,\n",
              "  773234,\n",
              "  772729,\n",
              "  773455,\n",
              "  773196,\n",
              "  773172,\n",
              "  773002,\n",
              "  772988,\n",
              "  773367,\n",
              "  772733,\n",
              "  773112,\n",
              "  773113,\n",
              "  772704,\n",
              "  773028,\n",
              "  773453,\n",
              "  773431,\n",
              "  773030,\n",
              "  773160,\n",
              "  773457,\n",
              "  773356,\n",
              "  772728,\n",
              "  773423,\n",
              "  773471,\n",
              "  773024,\n",
              "  773059,\n",
              "  773064,\n",
              "  773074,\n",
              "  773077,\n",
              "  773151,\n",
              "  773467,\n",
              "  773273,\n",
              "  773076,\n",
              "  773279,\n",
              "  773269,\n",
              "  773248,\n",
              "  773472,\n",
              "  85],\n",
              " [773425,\n",
              "  773080,\n",
              "  773459,\n",
              "  772705,\n",
              "  773452,\n",
              "  773202,\n",
              "  773122,\n",
              "  773390,\n",
              "  773141,\n",
              "  773144,\n",
              "  772735,\n",
              "  773161,\n",
              "  773182,\n",
              "  773364,\n",
              "  773340,\n",
              "  773259,\n",
              "  773034,\n",
              "  772990,\n",
              "  772987,\n",
              "  773001,\n",
              "  773234,\n",
              "  772729,\n",
              "  773455,\n",
              "  773196,\n",
              "  773172,\n",
              "  773002,\n",
              "  772988,\n",
              "  773367,\n",
              "  772733,\n",
              "  773112,\n",
              "  773113,\n",
              "  772704,\n",
              "  773028,\n",
              "  773453,\n",
              "  773431,\n",
              "  773030,\n",
              "  773160,\n",
              "  773457,\n",
              "  773356,\n",
              "  772728,\n",
              "  773423,\n",
              "  773471,\n",
              "  773024,\n",
              "  773059,\n",
              "  773064,\n",
              "  773074,\n",
              "  773077,\n",
              "  773151,\n",
              "  773467,\n",
              "  773273,\n",
              "  773076,\n",
              "  773279,\n",
              "  773269,\n",
              "  773248,\n",
              "  773472,\n",
              "  773019,\n",
              "  773029,\n",
              "  773078,\n",
              "  772995,\n",
              "  773329,\n",
              "  773033,\n",
              "  773251,\n",
              "  773343,\n",
              "  773339,\n",
              "  773183,\n",
              "  773184,\n",
              "  70],\n",
              " [773425,\n",
              "  773080,\n",
              "  773459,\n",
              "  772705,\n",
              "  773452,\n",
              "  773202,\n",
              "  773122,\n",
              "  773390,\n",
              "  773141,\n",
              "  773144,\n",
              "  772735,\n",
              "  773161,\n",
              "  773182,\n",
              "  773364,\n",
              "  773340,\n",
              "  773259,\n",
              "  773034,\n",
              "  772990,\n",
              "  772987,\n",
              "  773001,\n",
              "  773234,\n",
              "  772729,\n",
              "  773455,\n",
              "  773196,\n",
              "  773172,\n",
              "  773002,\n",
              "  772988,\n",
              "  773367,\n",
              "  772733,\n",
              "  773112,\n",
              "  773113,\n",
              "  772704,\n",
              "  773028,\n",
              "  773453,\n",
              "  773431,\n",
              "  773030,\n",
              "  773160,\n",
              "  773457,\n",
              "  773356,\n",
              "  772728,\n",
              "  773423,\n",
              "  773471,\n",
              "  773024,\n",
              "  773059,\n",
              "  773064,\n",
              "  773074,\n",
              "  773077,\n",
              "  773151,\n",
              "  773467,\n",
              "  773273,\n",
              "  773076,\n",
              "  773279,\n",
              "  773269,\n",
              "  773248,\n",
              "  773472,\n",
              "  773019,\n",
              "  773029,\n",
              "  773078,\n",
              "  772995,\n",
              "  773329,\n",
              "  773033,\n",
              "  773251,\n",
              "  773343,\n",
              "  773339,\n",
              "  773183,\n",
              "  773184,\n",
              "  773294,\n",
              "  772991,\n",
              "  773114,\n",
              "  773152,\n",
              "  773194,\n",
              "  773187,\n",
              "  772700,\n",
              "  773460,\n",
              "  773021,\n",
              "  773195,\n",
              "  773101,\n",
              "  773387,\n",
              "  773132,\n",
              "  773103,\n",
              "  70],\n",
              " [772990,\n",
              "  772705,\n",
              "  772988,\n",
              "  773122,\n",
              "  773313,\n",
              "  772987,\n",
              "  773172,\n",
              "  773173,\n",
              "  773064,\n",
              "  773164,\n",
              "  773171,\n",
              "  773074,\n",
              "  773144,\n",
              "  773165,\n",
              "  773390,\n",
              "  773178,\n",
              "  773279,\n",
              "  773196,\n",
              "  773269,\n",
              "  773182,\n",
              "  773248,\n",
              "  773234,\n",
              "  773453,\n",
              "  773471,\n",
              "  773187,\n",
              "  773202,\n",
              "  773034,\n",
              "  773080,\n",
              "  773029,\n",
              "  773030,\n",
              "  773024,\n",
              "  773316,\n",
              "  773177,\n",
              "  773273,\n",
              "  773174,\n",
              "  773151,\n",
              "  773076,\n",
              "  70],\n",
              " [772990,\n",
              "  772705,\n",
              "  772988,\n",
              "  773122,\n",
              "  773313,\n",
              "  772987,\n",
              "  773172,\n",
              "  773173,\n",
              "  773064,\n",
              "  773164,\n",
              "  773171,\n",
              "  773074,\n",
              "  773144,\n",
              "  773165,\n",
              "  773390,\n",
              "  773178,\n",
              "  773279,\n",
              "  773196,\n",
              "  773269,\n",
              "  773182,\n",
              "  773248,\n",
              "  773234,\n",
              "  773453,\n",
              "  773471,\n",
              "  773187,\n",
              "  773202,\n",
              "  773034,\n",
              "  773080,\n",
              "  773029,\n",
              "  773030,\n",
              "  773024,\n",
              "  773316,\n",
              "  773177,\n",
              "  773273,\n",
              "  773174,\n",
              "  773151,\n",
              "  773076,\n",
              "  773001,\n",
              "  772729,\n",
              "  773322,\n",
              "  773312,\n",
              "  773077,\n",
              "  772995,\n",
              "  773160,\n",
              "  773114,\n",
              "  772728,\n",
              "  773033,\n",
              "  772700,\n",
              "  773455,\n",
              "  773329,\n",
              "  773343,\n",
              "  773112,\n",
              "  772704,\n",
              "  773356,\n",
              "  773002,\n",
              "  773294,\n",
              "  85],\n",
              " [772990,\n",
              "  772705,\n",
              "  772988,\n",
              "  773122,\n",
              "  773313,\n",
              "  772987,\n",
              "  773172,\n",
              "  773173,\n",
              "  773064,\n",
              "  773164,\n",
              "  773171,\n",
              "  773074,\n",
              "  773144,\n",
              "  773165,\n",
              "  773390,\n",
              "  773178,\n",
              "  773279,\n",
              "  773196,\n",
              "  773269,\n",
              "  773182,\n",
              "  773248,\n",
              "  773234,\n",
              "  773453,\n",
              "  773471,\n",
              "  773187,\n",
              "  773202,\n",
              "  773034,\n",
              "  773080,\n",
              "  773029,\n",
              "  773030,\n",
              "  773024,\n",
              "  773316,\n",
              "  773177,\n",
              "  773273,\n",
              "  773174,\n",
              "  773151,\n",
              "  773076,\n",
              "  773001,\n",
              "  772729,\n",
              "  773322,\n",
              "  773312,\n",
              "  773077,\n",
              "  772995,\n",
              "  773160,\n",
              "  773114,\n",
              "  772728,\n",
              "  773033,\n",
              "  772700,\n",
              "  773455,\n",
              "  773329,\n",
              "  773343,\n",
              "  773112,\n",
              "  772704,\n",
              "  773356,\n",
              "  773002,\n",
              "  773294,\n",
              "  772991,\n",
              "  773128,\n",
              "  773379,\n",
              "  773419,\n",
              "  85],\n",
              " [772990,\n",
              "  772705,\n",
              "  772988,\n",
              "  773122,\n",
              "  773313,\n",
              "  772987,\n",
              "  773172,\n",
              "  773173,\n",
              "  773064,\n",
              "  773164,\n",
              "  773171,\n",
              "  773074,\n",
              "  773144,\n",
              "  773165,\n",
              "  773390,\n",
              "  773178,\n",
              "  773279,\n",
              "  773196,\n",
              "  773269,\n",
              "  773182,\n",
              "  773248,\n",
              "  773234,\n",
              "  773453,\n",
              "  773471,\n",
              "  773187,\n",
              "  773202,\n",
              "  773034,\n",
              "  773080,\n",
              "  773029,\n",
              "  773030,\n",
              "  773024,\n",
              "  773316,\n",
              "  773177,\n",
              "  773273,\n",
              "  773174,\n",
              "  773151,\n",
              "  773076,\n",
              "  773001,\n",
              "  772729,\n",
              "  773322,\n",
              "  773312,\n",
              "  773077,\n",
              "  772995,\n",
              "  773160,\n",
              "  773114,\n",
              "  772728,\n",
              "  773033,\n",
              "  772700,\n",
              "  773455,\n",
              "  773329,\n",
              "  773343,\n",
              "  773112,\n",
              "  772704,\n",
              "  773356,\n",
              "  773002,\n",
              "  773294,\n",
              "  772991,\n",
              "  773128,\n",
              "  773379,\n",
              "  773419,\n",
              "  772997,\n",
              "  70],\n",
              " [772990,\n",
              "  772705,\n",
              "  772988,\n",
              "  773122,\n",
              "  773313,\n",
              "  772987,\n",
              "  773172,\n",
              "  773173,\n",
              "  773064,\n",
              "  773164,\n",
              "  773171,\n",
              "  773074,\n",
              "  773144,\n",
              "  773165,\n",
              "  773390,\n",
              "  773178,\n",
              "  773279,\n",
              "  773196,\n",
              "  773269,\n",
              "  773182,\n",
              "  773248,\n",
              "  773234,\n",
              "  773453,\n",
              "  773471,\n",
              "  773187,\n",
              "  773202,\n",
              "  773034,\n",
              "  773080,\n",
              "  773029,\n",
              "  773030,\n",
              "  773024,\n",
              "  773316,\n",
              "  773177,\n",
              "  773273,\n",
              "  773174,\n",
              "  773151,\n",
              "  773076,\n",
              "  773001,\n",
              "  772729,\n",
              "  773322,\n",
              "  773312,\n",
              "  773077,\n",
              "  772995,\n",
              "  773160,\n",
              "  773114,\n",
              "  772728,\n",
              "  773033,\n",
              "  772700,\n",
              "  773455,\n",
              "  773329,\n",
              "  773343,\n",
              "  773112,\n",
              "  772704,\n",
              "  773356,\n",
              "  773002,\n",
              "  773294,\n",
              "  772991,\n",
              "  773128,\n",
              "  773379,\n",
              "  773419,\n",
              "  772997,\n",
              "  773402,\n",
              "  772994,\n",
              "  773157,\n",
              "  773008,\n",
              "  772734,\n",
              "  773129,\n",
              "  773244,\n",
              "  773345,\n",
              "  70],\n",
              " [772990,\n",
              "  772705,\n",
              "  772988,\n",
              "  773122,\n",
              "  773313,\n",
              "  772987,\n",
              "  773172,\n",
              "  773173,\n",
              "  773064,\n",
              "  773164,\n",
              "  773171,\n",
              "  773074,\n",
              "  773144,\n",
              "  773165,\n",
              "  773390,\n",
              "  773178,\n",
              "  773279,\n",
              "  773196,\n",
              "  773269,\n",
              "  773182,\n",
              "  773248,\n",
              "  773234,\n",
              "  773453,\n",
              "  773471,\n",
              "  773187,\n",
              "  773202,\n",
              "  773034,\n",
              "  773080,\n",
              "  773029,\n",
              "  773030,\n",
              "  773024,\n",
              "  773316,\n",
              "  773177,\n",
              "  773273,\n",
              "  773174,\n",
              "  773151,\n",
              "  773076,\n",
              "  773001,\n",
              "  772729,\n",
              "  773322,\n",
              "  773312,\n",
              "  773077,\n",
              "  772995,\n",
              "  773160,\n",
              "  773114,\n",
              "  772728,\n",
              "  773033,\n",
              "  772700,\n",
              "  773455,\n",
              "  773329,\n",
              "  773343,\n",
              "  773112,\n",
              "  772704,\n",
              "  773356,\n",
              "  773002,\n",
              "  773294,\n",
              "  772991,\n",
              "  773128,\n",
              "  773379,\n",
              "  773419,\n",
              "  772997,\n",
              "  773402,\n",
              "  772994,\n",
              "  773157,\n",
              "  773008,\n",
              "  772734,\n",
              "  773129,\n",
              "  773244,\n",
              "  773345,\n",
              "  772998,\n",
              "  773130,\n",
              "  773346,\n",
              "  85],\n",
              " [772990,\n",
              "  772705,\n",
              "  772988,\n",
              "  773122,\n",
              "  773313,\n",
              "  772987,\n",
              "  773172,\n",
              "  773173,\n",
              "  773064,\n",
              "  773164,\n",
              "  773171,\n",
              "  773074,\n",
              "  773144,\n",
              "  773165,\n",
              "  773390,\n",
              "  773178,\n",
              "  773279,\n",
              "  773196,\n",
              "  773269,\n",
              "  773182,\n",
              "  773248,\n",
              "  773234,\n",
              "  773453,\n",
              "  773471,\n",
              "  773187,\n",
              "  773202,\n",
              "  773034,\n",
              "  773080,\n",
              "  773029,\n",
              "  773030,\n",
              "  773024,\n",
              "  773316,\n",
              "  773177,\n",
              "  773273,\n",
              "  773174,\n",
              "  773151,\n",
              "  773076,\n",
              "  773001,\n",
              "  772729,\n",
              "  773322,\n",
              "  773312,\n",
              "  773077,\n",
              "  772995,\n",
              "  773160,\n",
              "  773114,\n",
              "  772728,\n",
              "  773033,\n",
              "  772700,\n",
              "  773455,\n",
              "  773329,\n",
              "  773343,\n",
              "  773112,\n",
              "  772704,\n",
              "  773356,\n",
              "  773002,\n",
              "  773294,\n",
              "  772991,\n",
              "  773128,\n",
              "  773379,\n",
              "  773419,\n",
              "  772997,\n",
              "  773402,\n",
              "  772994,\n",
              "  773157,\n",
              "  773008,\n",
              "  772734,\n",
              "  773129,\n",
              "  773244,\n",
              "  773345,\n",
              "  772998,\n",
              "  773130,\n",
              "  773346,\n",
              "  772701,\n",
              "  773119,\n",
              "  773115,\n",
              "  772702,\n",
              "  773009,\n",
              "  772698,\n",
              "  773361,\n",
              "  773340,\n",
              "  773099,\n",
              "  772699,\n",
              "  772703,\n",
              "  773161,\n",
              "  773012,\n",
              "  773117,\n",
              "  773364,\n",
              "  773460,\n",
              "  773310,\n",
              "  773259,\n",
              "  772738,\n",
              "  70],\n",
              " [703742,\n",
              "  704228,\n",
              "  703721,\n",
              "  704224,\n",
              "  703894,\n",
              "  704215,\n",
              "  704071,\n",
              "  703943,\n",
              "  703939,\n",
              "  703900,\n",
              "  704227,\n",
              "  703722,\n",
              "  703942,\n",
              "  703732,\n",
              "  703726,\n",
              "  703737,\n",
              "  703723,\n",
              "  704221,\n",
              "  703902,\n",
              "  703741,\n",
              "  704229,\n",
              "  704226,\n",
              "  70],\n",
              " [703742,\n",
              "  704228,\n",
              "  703721,\n",
              "  704224,\n",
              "  703894,\n",
              "  704215,\n",
              "  704071,\n",
              "  703943,\n",
              "  703939,\n",
              "  703900,\n",
              "  704227,\n",
              "  703722,\n",
              "  703942,\n",
              "  703732,\n",
              "  703726,\n",
              "  703737,\n",
              "  703723,\n",
              "  704221,\n",
              "  703902,\n",
              "  703741,\n",
              "  704229,\n",
              "  704226,\n",
              "  703940,\n",
              "  70],\n",
              " [703742,\n",
              "  704228,\n",
              "  703721,\n",
              "  704224,\n",
              "  703894,\n",
              "  704215,\n",
              "  704071,\n",
              "  703943,\n",
              "  703939,\n",
              "  703900,\n",
              "  704227,\n",
              "  703722,\n",
              "  703942,\n",
              "  703732,\n",
              "  703726,\n",
              "  703737,\n",
              "  703723,\n",
              "  704221,\n",
              "  703902,\n",
              "  703741,\n",
              "  704229,\n",
              "  704226,\n",
              "  703940,\n",
              "  704214,\n",
              "  703725,\n",
              "  703729,\n",
              "  704082,\n",
              "  703948,\n",
              "  703895,\n",
              "  85],\n",
              " [703742,\n",
              "  704228,\n",
              "  703721,\n",
              "  704224,\n",
              "  703894,\n",
              "  704215,\n",
              "  704071,\n",
              "  703943,\n",
              "  703939,\n",
              "  703900,\n",
              "  704227,\n",
              "  703722,\n",
              "  703942,\n",
              "  703732,\n",
              "  703726,\n",
              "  703737,\n",
              "  703723,\n",
              "  704221,\n",
              "  703902,\n",
              "  703741,\n",
              "  704229,\n",
              "  704226,\n",
              "  703940,\n",
              "  704214,\n",
              "  703725,\n",
              "  703729,\n",
              "  704082,\n",
              "  703948,\n",
              "  703895,\n",
              "  703901,\n",
              "  704218,\n",
              "  703727,\n",
              "  703735,\n",
              "  704222,\n",
              "  703896,\n",
              "  85],\n",
              " [703742,\n",
              "  704228,\n",
              "  703721,\n",
              "  704224,\n",
              "  703894,\n",
              "  704215,\n",
              "  704071,\n",
              "  703943,\n",
              "  703939,\n",
              "  703900,\n",
              "  704227,\n",
              "  703722,\n",
              "  703942,\n",
              "  703732,\n",
              "  703726,\n",
              "  703737,\n",
              "  703723,\n",
              "  704221,\n",
              "  703902,\n",
              "  703741,\n",
              "  704229,\n",
              "  704226,\n",
              "  703940,\n",
              "  704214,\n",
              "  703725,\n",
              "  703729,\n",
              "  704082,\n",
              "  703948,\n",
              "  703895,\n",
              "  703901,\n",
              "  704218,\n",
              "  703727,\n",
              "  703735,\n",
              "  704222,\n",
              "  703896,\n",
              "  703728,\n",
              "  703897,\n",
              "  85],\n",
              " [703742,\n",
              "  704228,\n",
              "  703721,\n",
              "  704224,\n",
              "  703894,\n",
              "  704215,\n",
              "  704071,\n",
              "  703943,\n",
              "  703939,\n",
              "  703900,\n",
              "  704227,\n",
              "  703722,\n",
              "  703942,\n",
              "  703732,\n",
              "  703726,\n",
              "  703737,\n",
              "  703723,\n",
              "  704221,\n",
              "  703902,\n",
              "  703741,\n",
              "  704229,\n",
              "  704226,\n",
              "  703940,\n",
              "  704214,\n",
              "  703725,\n",
              "  703729,\n",
              "  704082,\n",
              "  703948,\n",
              "  703895,\n",
              "  703901,\n",
              "  704218,\n",
              "  703727,\n",
              "  703735,\n",
              "  704222,\n",
              "  703896,\n",
              "  703728,\n",
              "  703897,\n",
              "  704237,\n",
              "  703898,\n",
              "  85],\n",
              " [703742,\n",
              "  704228,\n",
              "  703721,\n",
              "  704224,\n",
              "  703894,\n",
              "  704215,\n",
              "  704071,\n",
              "  703943,\n",
              "  703939,\n",
              "  703900,\n",
              "  704227,\n",
              "  703722,\n",
              "  703942,\n",
              "  703732,\n",
              "  703726,\n",
              "  703737,\n",
              "  703723,\n",
              "  704221,\n",
              "  703902,\n",
              "  703741,\n",
              "  704229,\n",
              "  704226,\n",
              "  703940,\n",
              "  704214,\n",
              "  703725,\n",
              "  703729,\n",
              "  704082,\n",
              "  703948,\n",
              "  85],\n",
              " [703742,\n",
              "  704228,\n",
              "  703721,\n",
              "  704224,\n",
              "  703894,\n",
              "  704215,\n",
              "  704071,\n",
              "  703943,\n",
              "  703939,\n",
              "  703900,\n",
              "  704227,\n",
              "  703722,\n",
              "  703942,\n",
              "  703732,\n",
              "  703726,\n",
              "  703737,\n",
              "  703723,\n",
              "  704221,\n",
              "  703902,\n",
              "  703741,\n",
              "  704229,\n",
              "  704226,\n",
              "  703940,\n",
              "  704214,\n",
              "  703725,\n",
              "  703729,\n",
              "  704082,\n",
              "  703948,\n",
              "  703895,\n",
              "  703901,\n",
              "  704218,\n",
              "  703727,\n",
              "  703735,\n",
              "  704222,\n",
              "  85],\n",
              " [703742,\n",
              "  704228,\n",
              "  703721,\n",
              "  704224,\n",
              "  703894,\n",
              "  704215,\n",
              "  704071,\n",
              "  703943,\n",
              "  703939,\n",
              "  703900,\n",
              "  704227,\n",
              "  703722,\n",
              "  703942,\n",
              "  703732,\n",
              "  703726,\n",
              "  703737,\n",
              "  703723,\n",
              "  704221,\n",
              "  703902,\n",
              "  703741,\n",
              "  704229,\n",
              "  704226,\n",
              "  703940,\n",
              "  704214,\n",
              "  703725,\n",
              "  703729,\n",
              "  704082,\n",
              "  703948,\n",
              "  703895,\n",
              "  703901,\n",
              "  704218,\n",
              "  703727,\n",
              "  703735,\n",
              "  704222,\n",
              "  703896,\n",
              "  50],\n",
              " [703742,\n",
              "  704228,\n",
              "  703721,\n",
              "  704224,\n",
              "  703894,\n",
              "  704215,\n",
              "  704071,\n",
              "  703943,\n",
              "  703939,\n",
              "  703900,\n",
              "  704227,\n",
              "  703722,\n",
              "  703942,\n",
              "  703732,\n",
              "  703726,\n",
              "  703737,\n",
              "  703723,\n",
              "  704221,\n",
              "  703902,\n",
              "  703741,\n",
              "  704229,\n",
              "  704226,\n",
              "  703940,\n",
              "  704214,\n",
              "  703725,\n",
              "  703729,\n",
              "  704082,\n",
              "  703948,\n",
              "  703895,\n",
              "  703901,\n",
              "  704218,\n",
              "  703727,\n",
              "  703735,\n",
              "  704222,\n",
              "  703896,\n",
              "  703728,\n",
              "  703897,\n",
              "  85],\n",
              " [703742,\n",
              "  704228,\n",
              "  703721,\n",
              "  704224,\n",
              "  703894,\n",
              "  704215,\n",
              "  704071,\n",
              "  703943,\n",
              "  703939,\n",
              "  703900,\n",
              "  704227,\n",
              "  703722,\n",
              "  703942,\n",
              "  703732,\n",
              "  703726,\n",
              "  703737,\n",
              "  703723,\n",
              "  704221,\n",
              "  703902,\n",
              "  703741,\n",
              "  704229,\n",
              "  704226,\n",
              "  703940,\n",
              "  704214,\n",
              "  703725,\n",
              "  703729,\n",
              "  704082,\n",
              "  703948,\n",
              "  703895,\n",
              "  703901,\n",
              "  704218,\n",
              "  703727,\n",
              "  703735,\n",
              "  704222,\n",
              "  703896,\n",
              "  703728,\n",
              "  703897,\n",
              "  704237,\n",
              "  703898,\n",
              "  704240,\n",
              "  703966,\n",
              "  704067,\n",
              "  704125,\n",
              "  704069,\n",
              "  704068,\n",
              "  704066,\n",
              "  704065,\n",
              "  704064,\n",
              "  704063,\n",
              "  703967,\n",
              "  703981,\n",
              "  704062,\n",
              "  85],\n",
              " [768351, 85],\n",
              " [768351, 70],\n",
              " [768351, 50],\n",
              " [768351, 768396, 768472, 768405, 768330, 70],\n",
              " [768351, 768396, 768472, 768405, 768330, 768378, 768379, 768393, 768381, 50],\n",
              " [768351,\n",
              "  768396,\n",
              "  768472,\n",
              "  768405,\n",
              "  768330,\n",
              "  768378,\n",
              "  768379,\n",
              "  768393,\n",
              "  768381,\n",
              "  768586,\n",
              "  70],\n",
              " [768351, 85],\n",
              " [768351, 85],\n",
              " [768351, 70],\n",
              " [768351, 768396, 768472, 768405, 768330, 768378, 768379, 768393, 768381, 85],\n",
              " [768351,\n",
              "  768396,\n",
              "  768472,\n",
              "  768405,\n",
              "  768330,\n",
              "  768378,\n",
              "  768379,\n",
              "  768393,\n",
              "  768381,\n",
              "  768586,\n",
              "  768480,\n",
              "  768380,\n",
              "  768425,\n",
              "  70],\n",
              " [883036,\n",
              "  882654,\n",
              "  882932,\n",
              "  882924,\n",
              "  882923,\n",
              "  882922,\n",
              "  883076,\n",
              "  882537,\n",
              "  882653,\n",
              "  882616,\n",
              "  882626,\n",
              "  882900,\n",
              "  882545,\n",
              "  882940,\n",
              "  883064,\n",
              "  882609,\n",
              "  883142,\n",
              "  883092,\n",
              "  883037,\n",
              "  883289,\n",
              "  883060,\n",
              "  883173,\n",
              "  883143,\n",
              "  883040,\n",
              "  883286,\n",
              "  882602,\n",
              "  883041,\n",
              "  883186,\n",
              "  882617,\n",
              "  883075,\n",
              "  882547,\n",
              "  883288,\n",
              "  883177,\n",
              "  882633,\n",
              "  882701,\n",
              "  882551,\n",
              "  882707,\n",
              "  883148,\n",
              "  882665,\n",
              "  883189,\n",
              "  882638,\n",
              "  882573,\n",
              "  882556,\n",
              "  882554,\n",
              "  882580,\n",
              "  882899,\n",
              "  882921,\n",
              "  883055,\n",
              "  883233,\n",
              "  85],\n",
              " [883036,\n",
              "  882654,\n",
              "  882932,\n",
              "  882924,\n",
              "  882923,\n",
              "  882922,\n",
              "  883076,\n",
              "  882537,\n",
              "  882653,\n",
              "  882616,\n",
              "  882626,\n",
              "  882900,\n",
              "  882545,\n",
              "  882940,\n",
              "  883064,\n",
              "  882609,\n",
              "  883142,\n",
              "  883092,\n",
              "  883037,\n",
              "  883289,\n",
              "  883060,\n",
              "  883173,\n",
              "  883143,\n",
              "  883040,\n",
              "  883286,\n",
              "  882602,\n",
              "  883041,\n",
              "  883186,\n",
              "  882617,\n",
              "  883075,\n",
              "  882547,\n",
              "  883288,\n",
              "  883177,\n",
              "  882633,\n",
              "  882701,\n",
              "  882551,\n",
              "  882707,\n",
              "  883148,\n",
              "  882665,\n",
              "  883189,\n",
              "  882638,\n",
              "  882573,\n",
              "  882556,\n",
              "  882554,\n",
              "  882580,\n",
              "  882899,\n",
              "  882921,\n",
              "  883055,\n",
              "  883233,\n",
              "  882674,\n",
              "  883042,\n",
              "  883043,\n",
              "  882722,\n",
              "  882577,\n",
              "  882723,\n",
              "  883081,\n",
              "  882724,\n",
              "  882581,\n",
              "  883089,\n",
              "  882971,\n",
              "  882587,\n",
              "  883247,\n",
              "  85],\n",
              " [883036,\n",
              "  882654,\n",
              "  882932,\n",
              "  882924,\n",
              "  882923,\n",
              "  882922,\n",
              "  883076,\n",
              "  882537,\n",
              "  882653,\n",
              "  882616,\n",
              "  882626,\n",
              "  882900,\n",
              "  882545,\n",
              "  882940,\n",
              "  883064,\n",
              "  882609,\n",
              "  883142,\n",
              "  883092,\n",
              "  883037,\n",
              "  883289,\n",
              "  883060,\n",
              "  883173,\n",
              "  883143,\n",
              "  883040,\n",
              "  883286,\n",
              "  882602,\n",
              "  883041,\n",
              "  883186,\n",
              "  882617,\n",
              "  883075,\n",
              "  882547,\n",
              "  883288,\n",
              "  883177,\n",
              "  882633,\n",
              "  882701,\n",
              "  882551,\n",
              "  882707,\n",
              "  883148,\n",
              "  882665,\n",
              "  883189,\n",
              "  882638,\n",
              "  882573,\n",
              "  882556,\n",
              "  882554,\n",
              "  882580,\n",
              "  882899,\n",
              "  882921,\n",
              "  883055,\n",
              "  883233,\n",
              "  882674,\n",
              "  883042,\n",
              "  883043,\n",
              "  882722,\n",
              "  882577,\n",
              "  882723,\n",
              "  883081,\n",
              "  882724,\n",
              "  882581,\n",
              "  883089,\n",
              "  882971,\n",
              "  882587,\n",
              "  883247,\n",
              "  882618,\n",
              "  882675,\n",
              "  882975,\n",
              "  882610,\n",
              "  882672,\n",
              "  883088,\n",
              "  882646,\n",
              "  882676,\n",
              "  883045,\n",
              "  882658,\n",
              "  882647,\n",
              "  882645,\n",
              "  883259,\n",
              "  883084,\n",
              "  882566,\n",
              "  882562,\n",
              "  882668,\n",
              "  882561,\n",
              "  882671,\n",
              "  882659,\n",
              "  882650,\n",
              "  882947,\n",
              "  882563,\n",
              "  883047,\n",
              "  882656,\n",
              "  882996,\n",
              "  882625,\n",
              "  882926,\n",
              "  883023,\n",
              "  70],\n",
              " [883036,\n",
              "  882654,\n",
              "  882932,\n",
              "  882924,\n",
              "  882923,\n",
              "  882922,\n",
              "  883076,\n",
              "  882537,\n",
              "  882653,\n",
              "  882616,\n",
              "  882626,\n",
              "  882900,\n",
              "  882545,\n",
              "  882940,\n",
              "  883064,\n",
              "  882609,\n",
              "  883142,\n",
              "  883092,\n",
              "  883037,\n",
              "  883289,\n",
              "  883060,\n",
              "  883173,\n",
              "  883143,\n",
              "  883040,\n",
              "  883286,\n",
              "  882602,\n",
              "  883041,\n",
              "  883186,\n",
              "  882617,\n",
              "  883075,\n",
              "  882547,\n",
              "  883288,\n",
              "  883177,\n",
              "  882633,\n",
              "  882701,\n",
              "  882551,\n",
              "  882707,\n",
              "  883148,\n",
              "  882665,\n",
              "  883189,\n",
              "  882638,\n",
              "  882573,\n",
              "  882556,\n",
              "  882554,\n",
              "  882580,\n",
              "  882899,\n",
              "  882921,\n",
              "  883055,\n",
              "  883233,\n",
              "  882674,\n",
              "  883042,\n",
              "  883043,\n",
              "  882722,\n",
              "  882577,\n",
              "  882723,\n",
              "  883081,\n",
              "  882724,\n",
              "  882581,\n",
              "  883089,\n",
              "  882971,\n",
              "  882587,\n",
              "  883247,\n",
              "  882618,\n",
              "  882675,\n",
              "  882975,\n",
              "  882610,\n",
              "  882672,\n",
              "  883088,\n",
              "  882646,\n",
              "  882676,\n",
              "  883045,\n",
              "  882658,\n",
              "  882647,\n",
              "  882645,\n",
              "  883259,\n",
              "  883084,\n",
              "  882566,\n",
              "  882562,\n",
              "  882668,\n",
              "  882561,\n",
              "  882671,\n",
              "  882659,\n",
              "  882650,\n",
              "  882947,\n",
              "  882563,\n",
              "  883047,\n",
              "  882656,\n",
              "  882996,\n",
              "  882625,\n",
              "  882926,\n",
              "  883023,\n",
              "  882673,\n",
              "  882592,\n",
              "  883049,\n",
              "  883278,\n",
              "  883277,\n",
              "  882550,\n",
              "  882705,\n",
              "  882709,\n",
              "  882684,\n",
              "  882596,\n",
              "  882558,\n",
              "  937371,\n",
              "  882600,\n",
              "  883029,\n",
              "  941543,\n",
              "  883085,\n",
              "  882655,\n",
              "  882657,\n",
              "  882590,\n",
              "  883048,\n",
              "  882598,\n",
              "  882630,\n",
              "  882652,\n",
              "  882564,\n",
              "  882677,\n",
              "  85],\n",
              " [883036,\n",
              "  882654,\n",
              "  882932,\n",
              "  882924,\n",
              "  882923,\n",
              "  882922,\n",
              "  883076,\n",
              "  882537,\n",
              "  882653,\n",
              "  882616,\n",
              "  882626,\n",
              "  882900,\n",
              "  882545,\n",
              "  882940,\n",
              "  883064,\n",
              "  882609,\n",
              "  883142,\n",
              "  883092,\n",
              "  883037,\n",
              "  883289,\n",
              "  883060,\n",
              "  883173,\n",
              "  883143,\n",
              "  883040,\n",
              "  883286,\n",
              "  882602,\n",
              "  883041,\n",
              "  883186,\n",
              "  882617,\n",
              "  883075,\n",
              "  882547,\n",
              "  883288,\n",
              "  883177,\n",
              "  882633,\n",
              "  882701,\n",
              "  882551,\n",
              "  882707,\n",
              "  883148,\n",
              "  882665,\n",
              "  883189,\n",
              "  882638,\n",
              "  882573,\n",
              "  882556,\n",
              "  882554,\n",
              "  882580,\n",
              "  882899,\n",
              "  882921,\n",
              "  883055,\n",
              "  883233,\n",
              "  882674,\n",
              "  883042,\n",
              "  883043,\n",
              "  882722,\n",
              "  882577,\n",
              "  882723,\n",
              "  883081,\n",
              "  882724,\n",
              "  882581,\n",
              "  883089,\n",
              "  882971,\n",
              "  882587,\n",
              "  883247,\n",
              "  882618,\n",
              "  882675,\n",
              "  882975,\n",
              "  882610,\n",
              "  882672,\n",
              "  883088,\n",
              "  882646,\n",
              "  882676,\n",
              "  883045,\n",
              "  882658,\n",
              "  882647,\n",
              "  882645,\n",
              "  883259,\n",
              "  883084,\n",
              "  882566,\n",
              "  882562,\n",
              "  882668,\n",
              "  882561,\n",
              "  882671,\n",
              "  882659,\n",
              "  882650,\n",
              "  882947,\n",
              "  882563,\n",
              "  883047,\n",
              "  882656,\n",
              "  882996,\n",
              "  882625,\n",
              "  882926,\n",
              "  883023,\n",
              "  882673,\n",
              "  882592,\n",
              "  883049,\n",
              "  883278,\n",
              "  883277,\n",
              "  882550,\n",
              "  882705,\n",
              "  882709,\n",
              "  882684,\n",
              "  882596,\n",
              "  882558,\n",
              "  937371,\n",
              "  882600,\n",
              "  883029,\n",
              "  941543,\n",
              "  883085,\n",
              "  882655,\n",
              "  882657,\n",
              "  882590,\n",
              "  883048,\n",
              "  882598,\n",
              "  882630,\n",
              "  882652,\n",
              "  882564,\n",
              "  882677,\n",
              "  882629,\n",
              "  882608,\n",
              "  883169,\n",
              "  883046,\n",
              "  883073,\n",
              "  882711,\n",
              "  882685,\n",
              "  882559,\n",
              "  882611,\n",
              "  882713,\n",
              "  882712,\n",
              "  882721,\n",
              "  883301,\n",
              "  882584,\n",
              "  883271,\n",
              "  882679,\n",
              "  883027,\n",
              "  882565,\n",
              "  883302,\n",
              "  882620,\n",
              "  85],\n",
              " [883036,\n",
              "  882654,\n",
              "  882932,\n",
              "  882924,\n",
              "  882923,\n",
              "  882922,\n",
              "  883076,\n",
              "  882537,\n",
              "  882653,\n",
              "  882616,\n",
              "  882626,\n",
              "  882900,\n",
              "  882545,\n",
              "  882940,\n",
              "  883064,\n",
              "  882609,\n",
              "  883142,\n",
              "  883092,\n",
              "  883037,\n",
              "  883289,\n",
              "  883060,\n",
              "  883173,\n",
              "  883143,\n",
              "  883040,\n",
              "  883286,\n",
              "  882602,\n",
              "  883041,\n",
              "  883186,\n",
              "  882617,\n",
              "  883075,\n",
              "  882547,\n",
              "  883288,\n",
              "  883177,\n",
              "  882633,\n",
              "  882701,\n",
              "  882551,\n",
              "  882707,\n",
              "  883148,\n",
              "  882665,\n",
              "  883189,\n",
              "  882638,\n",
              "  882573,\n",
              "  882556,\n",
              "  882554,\n",
              "  882580,\n",
              "  882899,\n",
              "  882921,\n",
              "  883055,\n",
              "  883233,\n",
              "  882674,\n",
              "  883042,\n",
              "  883043,\n",
              "  882722,\n",
              "  882577,\n",
              "  882723,\n",
              "  883081,\n",
              "  882724,\n",
              "  882581,\n",
              "  883089,\n",
              "  882971,\n",
              "  882587,\n",
              "  883247,\n",
              "  882618,\n",
              "  882675,\n",
              "  85],\n",
              " [883036,\n",
              "  882654,\n",
              "  882932,\n",
              "  882924,\n",
              "  882923,\n",
              "  882922,\n",
              "  883076,\n",
              "  882537,\n",
              "  882653,\n",
              "  882616,\n",
              "  882626,\n",
              "  882900,\n",
              "  882545,\n",
              "  882940,\n",
              "  883064,\n",
              "  882609,\n",
              "  883142,\n",
              "  883092,\n",
              "  883037,\n",
              "  883289,\n",
              "  883060,\n",
              "  883173,\n",
              "  883143,\n",
              "  883040,\n",
              "  883286,\n",
              "  882602,\n",
              "  883041,\n",
              "  883186,\n",
              "  882617,\n",
              "  883075,\n",
              "  882547,\n",
              "  883288,\n",
              "  883177,\n",
              "  882633,\n",
              "  882701,\n",
              "  882551,\n",
              "  882707,\n",
              "  883148,\n",
              "  882665,\n",
              "  883189,\n",
              "  882638,\n",
              "  882573,\n",
              "  882556,\n",
              "  882554,\n",
              "  882580,\n",
              "  882899,\n",
              "  882921,\n",
              "  883055,\n",
              "  883233,\n",
              "  882674,\n",
              "  883042,\n",
              "  883043,\n",
              "  882722,\n",
              "  882577,\n",
              "  882723,\n",
              "  883081,\n",
              "  882724,\n",
              "  882581,\n",
              "  883089,\n",
              "  882971,\n",
              "  882587,\n",
              "  883247,\n",
              "  882618,\n",
              "  882675,\n",
              "  882975,\n",
              "  882610,\n",
              "  882672,\n",
              "  883088,\n",
              "  882646,\n",
              "  85],\n",
              " [883036,\n",
              "  882654,\n",
              "  882932,\n",
              "  882924,\n",
              "  882923,\n",
              "  882922,\n",
              "  883076,\n",
              "  882537,\n",
              "  882653,\n",
              "  882616,\n",
              "  882626,\n",
              "  882900,\n",
              "  882545,\n",
              "  882940,\n",
              "  883064,\n",
              "  882609,\n",
              "  883142,\n",
              "  883092,\n",
              "  883037,\n",
              "  883289,\n",
              "  883060,\n",
              "  883173,\n",
              "  883143,\n",
              "  883040,\n",
              "  883286,\n",
              "  882602,\n",
              "  883041,\n",
              "  883186,\n",
              "  882617,\n",
              "  883075,\n",
              "  882547,\n",
              "  883288,\n",
              "  883177,\n",
              "  882633,\n",
              "  882701,\n",
              "  882551,\n",
              "  882707,\n",
              "  883148,\n",
              "  882665,\n",
              "  883189,\n",
              "  882638,\n",
              "  882573,\n",
              "  882556,\n",
              "  882554,\n",
              "  882580,\n",
              "  882899,\n",
              "  882921,\n",
              "  883055,\n",
              "  883233,\n",
              "  882674,\n",
              "  883042,\n",
              "  883043,\n",
              "  882722,\n",
              "  882577,\n",
              "  882723,\n",
              "  883081,\n",
              "  882724,\n",
              "  882581,\n",
              "  883089,\n",
              "  882971,\n",
              "  882587,\n",
              "  883247,\n",
              "  882618,\n",
              "  882675,\n",
              "  882975,\n",
              "  882610,\n",
              "  882672,\n",
              "  883088,\n",
              "  882646,\n",
              "  882676,\n",
              "  883045,\n",
              "  882658,\n",
              "  882647,\n",
              "  882645,\n",
              "  883259,\n",
              "  883084,\n",
              "  882566,\n",
              "  882562,\n",
              "  882668,\n",
              "  882561,\n",
              "  882671,\n",
              "  882659,\n",
              "  882650,\n",
              "  882947,\n",
              "  882563,\n",
              "  883047,\n",
              "  882656,\n",
              "  882996,\n",
              "  882625,\n",
              "  882926,\n",
              "  883023,\n",
              "  882673,\n",
              "  882592,\n",
              "  883049,\n",
              "  70],\n",
              " [883036,\n",
              "  882654,\n",
              "  882932,\n",
              "  882924,\n",
              "  882923,\n",
              "  882922,\n",
              "  883076,\n",
              "  882537,\n",
              "  882653,\n",
              "  882616,\n",
              "  882626,\n",
              "  882900,\n",
              "  882545,\n",
              "  882940,\n",
              "  883064,\n",
              "  882609,\n",
              "  883142,\n",
              "  883092,\n",
              "  883037,\n",
              "  883289,\n",
              "  883060,\n",
              "  883173,\n",
              "  883143,\n",
              "  883040,\n",
              "  883286,\n",
              "  882602,\n",
              "  883041,\n",
              "  883186,\n",
              "  882617,\n",
              "  883075,\n",
              "  882547,\n",
              "  883288,\n",
              "  883177,\n",
              "  882633,\n",
              "  882701,\n",
              "  882551,\n",
              "  882707,\n",
              "  883148,\n",
              "  882665,\n",
              "  883189,\n",
              "  882638,\n",
              "  882573,\n",
              "  882556,\n",
              "  882554,\n",
              "  882580,\n",
              "  882899,\n",
              "  882921,\n",
              "  883055,\n",
              "  883233,\n",
              "  882674,\n",
              "  883042,\n",
              "  883043,\n",
              "  882722,\n",
              "  882577,\n",
              "  882723,\n",
              "  883081,\n",
              "  882724,\n",
              "  882581,\n",
              "  883089,\n",
              "  882971,\n",
              "  882587,\n",
              "  883247,\n",
              "  882618,\n",
              "  882675,\n",
              "  882975,\n",
              "  882610,\n",
              "  882672,\n",
              "  883088,\n",
              "  882646,\n",
              "  882676,\n",
              "  883045,\n",
              "  882658,\n",
              "  882647,\n",
              "  882645,\n",
              "  883259,\n",
              "  883084,\n",
              "  882566,\n",
              "  882562,\n",
              "  882668,\n",
              "  882561,\n",
              "  882671,\n",
              "  882659,\n",
              "  882650,\n",
              "  882947,\n",
              "  882563,\n",
              "  883047,\n",
              "  882656,\n",
              "  882996,\n",
              "  882625,\n",
              "  882926,\n",
              "  883023,\n",
              "  882673,\n",
              "  882592,\n",
              "  883049,\n",
              "  883278,\n",
              "  883277,\n",
              "  882550,\n",
              "  882705,\n",
              "  882709,\n",
              "  882684,\n",
              "  882596,\n",
              "  882558,\n",
              "  937371,\n",
              "  882600,\n",
              "  883029,\n",
              "  941543,\n",
              "  85],\n",
              " [883036,\n",
              "  882654,\n",
              "  882932,\n",
              "  882924,\n",
              "  882923,\n",
              "  882922,\n",
              "  883076,\n",
              "  882537,\n",
              "  882653,\n",
              "  882616,\n",
              "  882626,\n",
              "  882900,\n",
              "  882545,\n",
              "  882940,\n",
              "  883064,\n",
              "  882609,\n",
              "  883142,\n",
              "  883092,\n",
              "  883037,\n",
              "  883289,\n",
              "  883060,\n",
              "  883173,\n",
              "  883143,\n",
              "  883040,\n",
              "  883286,\n",
              "  882602,\n",
              "  883041,\n",
              "  883186,\n",
              "  882617,\n",
              "  883075,\n",
              "  882547,\n",
              "  883288,\n",
              "  883177,\n",
              "  882633,\n",
              "  882701,\n",
              "  882551,\n",
              "  882707,\n",
              "  883148,\n",
              "  882665,\n",
              "  883189,\n",
              "  882638,\n",
              "  882573,\n",
              "  882556,\n",
              "  882554,\n",
              "  882580,\n",
              "  882899,\n",
              "  882921,\n",
              "  883055,\n",
              "  883233,\n",
              "  882674,\n",
              "  883042,\n",
              "  883043,\n",
              "  882722,\n",
              "  882577,\n",
              "  882723,\n",
              "  883081,\n",
              "  882724,\n",
              "  882581,\n",
              "  883089,\n",
              "  882971,\n",
              "  882587,\n",
              "  883247,\n",
              "  882618,\n",
              "  882675,\n",
              "  882975,\n",
              "  882610,\n",
              "  882672,\n",
              "  883088,\n",
              "  882646,\n",
              "  882676,\n",
              "  883045,\n",
              "  882658,\n",
              "  882647,\n",
              "  882645,\n",
              "  883259,\n",
              "  883084,\n",
              "  882566,\n",
              "  882562,\n",
              "  882668,\n",
              "  882561,\n",
              "  882671,\n",
              "  882659,\n",
              "  882650,\n",
              "  882947,\n",
              "  882563,\n",
              "  883047,\n",
              "  882656,\n",
              "  882996,\n",
              "  882625,\n",
              "  882926,\n",
              "  883023,\n",
              "  882673,\n",
              "  882592,\n",
              "  883049,\n",
              "  883278,\n",
              "  883277,\n",
              "  882550,\n",
              "  882705,\n",
              "  882709,\n",
              "  882684,\n",
              "  882596,\n",
              "  882558,\n",
              "  937371,\n",
              "  882600,\n",
              "  883029,\n",
              "  941543,\n",
              "  883085,\n",
              "  882655,\n",
              "  882657,\n",
              "  882590,\n",
              "  883048,\n",
              "  882598,\n",
              "  882630,\n",
              "  882652,\n",
              "  882564,\n",
              "  882677,\n",
              "  882629,\n",
              "  882608,\n",
              "  883169,\n",
              "  883046,\n",
              "  883073,\n",
              "  882711,\n",
              "  882685,\n",
              "  882559,\n",
              "  882611,\n",
              "  882713,\n",
              "  882712,\n",
              "  882721,\n",
              "  883301,\n",
              "  882584,\n",
              "  883271,\n",
              "  882679,\n",
              "  883027,\n",
              "  70],\n",
              " [883036,\n",
              "  882654,\n",
              "  882932,\n",
              "  882924,\n",
              "  882923,\n",
              "  882922,\n",
              "  883076,\n",
              "  882537,\n",
              "  882653,\n",
              "  882616,\n",
              "  882626,\n",
              "  882900,\n",
              "  882545,\n",
              "  882940,\n",
              "  883064,\n",
              "  882609,\n",
              "  883142,\n",
              "  883092,\n",
              "  883037,\n",
              "  883289,\n",
              "  883060,\n",
              "  883173,\n",
              "  883143,\n",
              "  883040,\n",
              "  883286,\n",
              "  882602,\n",
              "  883041,\n",
              "  883186,\n",
              "  882617,\n",
              "  883075,\n",
              "  882547,\n",
              "  883288,\n",
              "  883177,\n",
              "  882633,\n",
              "  882701,\n",
              "  882551,\n",
              "  882707,\n",
              "  883148,\n",
              "  882665,\n",
              "  883189,\n",
              "  882638,\n",
              "  882573,\n",
              "  882556,\n",
              "  882554,\n",
              "  882580,\n",
              "  882899,\n",
              "  882921,\n",
              "  883055,\n",
              "  883233,\n",
              "  882674,\n",
              "  883042,\n",
              "  883043,\n",
              "  882722,\n",
              "  882577,\n",
              "  882723,\n",
              "  883081,\n",
              "  882724,\n",
              "  882581,\n",
              "  883089,\n",
              "  882971,\n",
              "  882587,\n",
              "  883247,\n",
              "  882618,\n",
              "  882675,\n",
              "  882975,\n",
              "  882610,\n",
              "  882672,\n",
              "  883088,\n",
              "  882646,\n",
              "  882676,\n",
              "  883045,\n",
              "  882658,\n",
              "  882647,\n",
              "  882645,\n",
              "  883259,\n",
              "  883084,\n",
              "  882566,\n",
              "  882562,\n",
              "  882668,\n",
              "  882561,\n",
              "  882671,\n",
              "  882659,\n",
              "  882650,\n",
              "  882947,\n",
              "  882563,\n",
              "  883047,\n",
              "  882656,\n",
              "  882996,\n",
              "  882625,\n",
              "  882926,\n",
              "  883023,\n",
              "  882673,\n",
              "  882592,\n",
              "  883049,\n",
              "  883278,\n",
              "  883277,\n",
              "  882550,\n",
              "  882705,\n",
              "  882709,\n",
              "  882684,\n",
              "  882596,\n",
              "  882558,\n",
              "  937371,\n",
              "  882600,\n",
              "  883029,\n",
              "  941543,\n",
              "  883085,\n",
              "  882655,\n",
              "  882657,\n",
              "  882590,\n",
              "  883048,\n",
              "  882598,\n",
              "  882630,\n",
              "  882652,\n",
              "  882564,\n",
              "  882677,\n",
              "  882629,\n",
              "  882608,\n",
              "  883169,\n",
              "  883046,\n",
              "  883073,\n",
              "  882711,\n",
              "  882685,\n",
              "  882559,\n",
              "  882611,\n",
              "  882713,\n",
              "  882712,\n",
              "  882721,\n",
              "  883301,\n",
              "  882584,\n",
              "  883271,\n",
              "  882679,\n",
              "  883027,\n",
              "  882565,\n",
              "  883302,\n",
              "  882620,\n",
              "  973777,\n",
              "  883058,\n",
              "  883091,\n",
              "  882622,\n",
              "  882683,\n",
              "  882937,\n",
              "  882682,\n",
              "  882635,\n",
              "  882571,\n",
              "  70],\n",
              " [883036,\n",
              "  882654,\n",
              "  882932,\n",
              "  882924,\n",
              "  882923,\n",
              "  882922,\n",
              "  883076,\n",
              "  882537,\n",
              "  882653,\n",
              "  882616,\n",
              "  882626,\n",
              "  882900,\n",
              "  882545,\n",
              "  882940,\n",
              "  883064,\n",
              "  882609,\n",
              "  883142,\n",
              "  883092,\n",
              "  883037,\n",
              "  883289,\n",
              "  883060,\n",
              "  883173,\n",
              "  883143,\n",
              "  883040,\n",
              "  883286,\n",
              "  882602,\n",
              "  883041,\n",
              "  883186,\n",
              "  882617,\n",
              "  883075,\n",
              "  882547,\n",
              "  883288,\n",
              "  883177,\n",
              "  882633,\n",
              "  882701,\n",
              "  882551,\n",
              "  882707,\n",
              "  883148,\n",
              "  882665,\n",
              "  883189,\n",
              "  882638,\n",
              "  882573,\n",
              "  882556,\n",
              "  882554,\n",
              "  882580,\n",
              "  882899,\n",
              "  882921,\n",
              "  883055,\n",
              "  883233,\n",
              "  882674,\n",
              "  883042,\n",
              "  883043,\n",
              "  882722,\n",
              "  882577,\n",
              "  882723,\n",
              "  883081,\n",
              "  882724,\n",
              "  882581,\n",
              "  883089,\n",
              "  882971,\n",
              "  882587,\n",
              "  883247,\n",
              "  882618,\n",
              "  882675,\n",
              "  882975,\n",
              "  882610,\n",
              "  882672,\n",
              "  883088,\n",
              "  882646,\n",
              "  882676,\n",
              "  883045,\n",
              "  882658,\n",
              "  882647,\n",
              "  882645,\n",
              "  883259,\n",
              "  883084,\n",
              "  882566,\n",
              "  882562,\n",
              "  882668,\n",
              "  882561,\n",
              "  882671,\n",
              "  882659,\n",
              "  882650,\n",
              "  882947,\n",
              "  882563,\n",
              "  883047,\n",
              "  882656,\n",
              "  882996,\n",
              "  882625,\n",
              "  882926,\n",
              "  883023,\n",
              "  882673,\n",
              "  882592,\n",
              "  883049,\n",
              "  883278,\n",
              "  883277,\n",
              "  882550,\n",
              "  882705,\n",
              "  882709,\n",
              "  882684,\n",
              "  882596,\n",
              "  882558,\n",
              "  937371,\n",
              "  882600,\n",
              "  883029,\n",
              "  941543,\n",
              "  883085,\n",
              "  882655,\n",
              "  882657,\n",
              "  882590,\n",
              "  883048,\n",
              "  882598,\n",
              "  882630,\n",
              "  882652,\n",
              "  882564,\n",
              "  882677,\n",
              "  882629,\n",
              "  882608,\n",
              "  883169,\n",
              "  883046,\n",
              "  883073,\n",
              "  882711,\n",
              "  882685,\n",
              "  882559,\n",
              "  882611,\n",
              "  882713,\n",
              "  882712,\n",
              "  882721,\n",
              "  883301,\n",
              "  882584,\n",
              "  883271,\n",
              "  882679,\n",
              "  883027,\n",
              "  882565,\n",
              "  883302,\n",
              "  882620,\n",
              "  973777,\n",
              "  883058,\n",
              "  883091,\n",
              "  882622,\n",
              "  882683,\n",
              "  882937,\n",
              "  85],\n",
              " [729671,\n",
              "  729789,\n",
              "  730057,\n",
              "  729787,\n",
              "  730035,\n",
              "  730007,\n",
              "  730012,\n",
              "  730050,\n",
              "  730135,\n",
              "  730068,\n",
              "  730065,\n",
              "  85],\n",
              " [729671,\n",
              "  729789,\n",
              "  730057,\n",
              "  729787,\n",
              "  730035,\n",
              "  730007,\n",
              "  730012,\n",
              "  730050,\n",
              "  730135,\n",
              "  730068,\n",
              "  730065,\n",
              "  730054,\n",
              "  730059,\n",
              "  729779,\n",
              "  730053,\n",
              "  730071,\n",
              "  730075,\n",
              "  730017,\n",
              "  70],\n",
              " [729671,\n",
              "  729789,\n",
              "  730057,\n",
              "  729787,\n",
              "  730035,\n",
              "  730007,\n",
              "  730012,\n",
              "  730050,\n",
              "  730135,\n",
              "  730068,\n",
              "  730065,\n",
              "  730054,\n",
              "  730059,\n",
              "  729779,\n",
              "  730053,\n",
              "  730071,\n",
              "  730075,\n",
              "  730017,\n",
              "  730130,\n",
              "  729682,\n",
              "  729788,\n",
              "  729683,\n",
              "  730116,\n",
              "  730091,\n",
              "  50],\n",
              " [729671, 729789, 730057, 729787, 730035, 730007, 730012, 50],\n",
              " [729671,\n",
              "  729789,\n",
              "  730057,\n",
              "  729787,\n",
              "  730035,\n",
              "  730007,\n",
              "  730012,\n",
              "  730050,\n",
              "  730135,\n",
              "  730068,\n",
              "  730065,\n",
              "  730054,\n",
              "  730059,\n",
              "  729779,\n",
              "  730053,\n",
              "  730071,\n",
              "  85],\n",
              " [729671,\n",
              "  729789,\n",
              "  730057,\n",
              "  729787,\n",
              "  730035,\n",
              "  730007,\n",
              "  730012,\n",
              "  730050,\n",
              "  730135,\n",
              "  730068,\n",
              "  730065,\n",
              "  730054,\n",
              "  730059,\n",
              "  729779,\n",
              "  730053,\n",
              "  730071,\n",
              "  730075,\n",
              "  730017,\n",
              "  730130,\n",
              "  729682,\n",
              "  729788,\n",
              "  729683,\n",
              "  0],\n",
              " [729671,\n",
              "  729789,\n",
              "  730057,\n",
              "  729787,\n",
              "  730035,\n",
              "  730007,\n",
              "  730012,\n",
              "  730050,\n",
              "  730135,\n",
              "  730068,\n",
              "  730065,\n",
              "  730054,\n",
              "  730059,\n",
              "  729779,\n",
              "  730053,\n",
              "  730071,\n",
              "  730075,\n",
              "  730017,\n",
              "  730130,\n",
              "  729682,\n",
              "  729788,\n",
              "  729683,\n",
              "  730116,\n",
              "  730091,\n",
              "  730014,\n",
              "  730118,\n",
              "  730031,\n",
              "  729785,\n",
              "  730117,\n",
              "  730094,\n",
              "  730093,\n",
              "  0],\n",
              " [729671,\n",
              "  729789,\n",
              "  730057,\n",
              "  729787,\n",
              "  730035,\n",
              "  730007,\n",
              "  730012,\n",
              "  730050,\n",
              "  730135,\n",
              "  730068,\n",
              "  730065,\n",
              "  730054,\n",
              "  730059,\n",
              "  729779,\n",
              "  730053,\n",
              "  730071,\n",
              "  730075,\n",
              "  730017,\n",
              "  730130,\n",
              "  729682,\n",
              "  729788,\n",
              "  729683,\n",
              "  730116,\n",
              "  730091,\n",
              "  730014,\n",
              "  730118,\n",
              "  730031,\n",
              "  729785,\n",
              "  730117,\n",
              "  730094,\n",
              "  730093,\n",
              "  730088,\n",
              "  730127,\n",
              "  730018,\n",
              "  730006,\n",
              "  730016,\n",
              "  729796,\n",
              "  730110,\n",
              "  729795,\n",
              "  70],\n",
              " [779619,\n",
              "  779089,\n",
              "  779623,\n",
              "  779612,\n",
              "  779675,\n",
              "  779335,\n",
              "  779405,\n",
              "  779332,\n",
              "  779620,\n",
              "  779461,\n",
              "  779452,\n",
              "  779374,\n",
              "  779451,\n",
              "  779379,\n",
              "  779384,\n",
              "  779380,\n",
              "  779427,\n",
              "  779652,\n",
              "  779439,\n",
              "  779653,\n",
              "  779671,\n",
              "  779075,\n",
              "  779647,\n",
              "  779713,\n",
              "  779833,\n",
              "  779556,\n",
              "  779259,\n",
              "  779628,\n",
              "  779342,\n",
              "  779351,\n",
              "  779349,\n",
              "  779726,\n",
              "  779387,\n",
              "  779625,\n",
              "  779391,\n",
              "  779672,\n",
              "  779447,\n",
              "  85],\n",
              " [779619,\n",
              "  779089,\n",
              "  779623,\n",
              "  779612,\n",
              "  779675,\n",
              "  779335,\n",
              "  779405,\n",
              "  779332,\n",
              "  779620,\n",
              "  779461,\n",
              "  779452,\n",
              "  779374,\n",
              "  779451,\n",
              "  779379,\n",
              "  779384,\n",
              "  779380,\n",
              "  779427,\n",
              "  779652,\n",
              "  779439,\n",
              "  779653,\n",
              "  779671,\n",
              "  779075,\n",
              "  779647,\n",
              "  779713,\n",
              "  779833,\n",
              "  779556,\n",
              "  779259,\n",
              "  779628,\n",
              "  779342,\n",
              "  779351,\n",
              "  779349,\n",
              "  779726,\n",
              "  779387,\n",
              "  779625,\n",
              "  779391,\n",
              "  779672,\n",
              "  779447,\n",
              "  779527,\n",
              "  779490,\n",
              "  779431,\n",
              "  779449,\n",
              "  779668,\n",
              "  779727,\n",
              "  779728,\n",
              "  779624,\n",
              "  779078,\n",
              "  779076,\n",
              "  779441,\n",
              "  779347,\n",
              "  779725,\n",
              "  779260,\n",
              "  779437,\n",
              "  779546,\n",
              "  779331,\n",
              "  779651,\n",
              "  779276,\n",
              "  779385,\n",
              "  70],\n",
              " [779619,\n",
              "  779089,\n",
              "  779623,\n",
              "  779612,\n",
              "  779675,\n",
              "  779335,\n",
              "  779405,\n",
              "  779332,\n",
              "  779620,\n",
              "  779461,\n",
              "  779452,\n",
              "  779374,\n",
              "  779451,\n",
              "  779379,\n",
              "  779384,\n",
              "  779380,\n",
              "  779427,\n",
              "  779652,\n",
              "  779439,\n",
              "  779653,\n",
              "  779671,\n",
              "  779075,\n",
              "  779647,\n",
              "  779713,\n",
              "  779833,\n",
              "  779556,\n",
              "  779259,\n",
              "  779628,\n",
              "  779342,\n",
              "  779351,\n",
              "  779349,\n",
              "  779726,\n",
              "  779387,\n",
              "  779625,\n",
              "  779391,\n",
              "  779672,\n",
              "  779447,\n",
              "  779527,\n",
              "  779490,\n",
              "  779431,\n",
              "  779449,\n",
              "  779668,\n",
              "  779727,\n",
              "  779728,\n",
              "  779624,\n",
              "  779078,\n",
              "  779076,\n",
              "  779441,\n",
              "  779347,\n",
              "  779725,\n",
              "  779260,\n",
              "  779437,\n",
              "  779546,\n",
              "  779331,\n",
              "  779651,\n",
              "  779276,\n",
              "  779385,\n",
              "  779682,\n",
              "  779080,\n",
              "  779429,\n",
              "  779355,\n",
              "  779394,\n",
              "  779363,\n",
              "  779629,\n",
              "  779358,\n",
              "  779336,\n",
              "  779395,\n",
              "  779261,\n",
              "  779696,\n",
              "  779401,\n",
              "  779400,\n",
              "  779630,\n",
              "  779700,\n",
              "  779402,\n",
              "  779631,\n",
              "  779567,\n",
              "  779522,\n",
              "  779568,\n",
              "  779352,\n",
              "  779361,\n",
              "  779371,\n",
              "  779362,\n",
              "  85],\n",
              " [779619,\n",
              "  779089,\n",
              "  779623,\n",
              "  779612,\n",
              "  779675,\n",
              "  779335,\n",
              "  779405,\n",
              "  779332,\n",
              "  779620,\n",
              "  779461,\n",
              "  779452,\n",
              "  779374,\n",
              "  779451,\n",
              "  779379,\n",
              "  779384,\n",
              "  779380,\n",
              "  779427,\n",
              "  779652,\n",
              "  779439,\n",
              "  779653,\n",
              "  779671,\n",
              "  779075,\n",
              "  779647,\n",
              "  779713,\n",
              "  779833,\n",
              "  779556,\n",
              "  779259,\n",
              "  779628,\n",
              "  779342,\n",
              "  779351,\n",
              "  779349,\n",
              "  779726,\n",
              "  779387,\n",
              "  85],\n",
              " [779619,\n",
              "  779089,\n",
              "  779623,\n",
              "  779612,\n",
              "  779675,\n",
              "  779335,\n",
              "  779405,\n",
              "  779332,\n",
              "  779620,\n",
              "  779461,\n",
              "  779452,\n",
              "  779374,\n",
              "  779451,\n",
              "  779379,\n",
              "  779384,\n",
              "  779380,\n",
              "  779427,\n",
              "  779652,\n",
              "  779439,\n",
              "  779653,\n",
              "  779671,\n",
              "  779075,\n",
              "  779647,\n",
              "  779713,\n",
              "  779833,\n",
              "  779556,\n",
              "  779259,\n",
              "  779628,\n",
              "  779342,\n",
              "  779351,\n",
              "  779349,\n",
              "  779726,\n",
              "  779387,\n",
              "  779625,\n",
              "  779391,\n",
              "  779672,\n",
              "  779447,\n",
              "  779527,\n",
              "  779490,\n",
              "  779431,\n",
              "  779449,\n",
              "  779668,\n",
              "  779727,\n",
              "  779728,\n",
              "  779624,\n",
              "  779078,\n",
              "  779076,\n",
              "  779441,\n",
              "  779347,\n",
              "  779725,\n",
              "  779260,\n",
              "  779437,\n",
              "  779546,\n",
              "  779331,\n",
              "  779651,\n",
              "  779276,\n",
              "  779385,\n",
              "  779682,\n",
              "  779080,\n",
              "  779429,\n",
              "  70],\n",
              " [779619,\n",
              "  779089,\n",
              "  779623,\n",
              "  779612,\n",
              "  779675,\n",
              "  779335,\n",
              "  779405,\n",
              "  779332,\n",
              "  779620,\n",
              "  779461,\n",
              "  779452,\n",
              "  779374,\n",
              "  779451,\n",
              "  779379,\n",
              "  779384,\n",
              "  779380,\n",
              "  779427,\n",
              "  779652,\n",
              "  779439,\n",
              "  779653,\n",
              "  779671,\n",
              "  779075,\n",
              "  779647,\n",
              "  779713,\n",
              "  779833,\n",
              "  779556,\n",
              "  779259,\n",
              "  779628,\n",
              "  779342,\n",
              "  779351,\n",
              "  779349,\n",
              "  779726,\n",
              "  779387,\n",
              "  779625,\n",
              "  779391,\n",
              "  779672,\n",
              "  779447,\n",
              "  779527,\n",
              "  779490,\n",
              "  779431,\n",
              "  779449,\n",
              "  779668,\n",
              "  779727,\n",
              "  779728,\n",
              "  779624,\n",
              "  779078,\n",
              "  779076,\n",
              "  779441,\n",
              "  779347,\n",
              "  779725,\n",
              "  779260,\n",
              "  779437,\n",
              "  779546,\n",
              "  779331,\n",
              "  779651,\n",
              "  779276,\n",
              "  779385,\n",
              "  779682,\n",
              "  779080,\n",
              "  779429,\n",
              "  779355,\n",
              "  779394,\n",
              "  779363,\n",
              "  779629,\n",
              "  779358,\n",
              "  779336,\n",
              "  779395,\n",
              "  779261,\n",
              "  779696,\n",
              "  779401,\n",
              "  779400,\n",
              "  779630,\n",
              "  779700,\n",
              "  779402,\n",
              "  779631,\n",
              "  779567,\n",
              "  779522,\n",
              "  779568,\n",
              "  779352,\n",
              "  779361,\n",
              "  779371,\n",
              "  779362,\n",
              "  779343,\n",
              "  779614,\n",
              "  779613,\n",
              "  779369,\n",
              "  70]]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "def score_to_grade_bucket(score):\n",
        "    \"\"\"\n",
        "    Converts a score to a grade bucket\n",
        "    \"\"\"\n",
        "    if score >= 85:\n",
        "        return 85\n",
        "    elif score >= 70:\n",
        "        return 70\n",
        "    elif score >= 50:\n",
        "        return 50\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "def get_resource_sets_per_student(student_id):\n",
        "    \"\"\"\n",
        "    Returns the set of resources a student has interacted with before an assessment.\n",
        "    \"\"\"\n",
        "    global student_vle_df\n",
        "    global student_assessment_df\n",
        "    student_vle_interaction = get_vle_interaction_by_student(student_id)\n",
        "    student_assessment = student_assessment_df[student_assessment_df['id_student'] == student_id]\n",
        "    student_vle_sets = []\n",
        "    for index, assessment in student_assessment.iterrows():\n",
        "        assessment_date = assessment[\"date_submitted\"]\n",
        "        student_vle_set = student_vle_interaction[student_vle_interaction[\"date\"] < assessment_date] # ?  Say there are 3 assessments, we are saying that resources used before assessment 1 also affect the outcome of assessment 3\n",
        "        student_vle_set : np.ndarray = student_vle_set[\"id_site\"].unique()\n",
        "        student_vle_set = student_vle_set.tolist()\n",
        "        student_vle_set.append(score_to_grade_bucket(assessment[\"score\"])) # ? Should I use the weighted Score?\n",
        "        student_vle_sets.append(student_vle_set)\n",
        "    return student_vle_sets\n",
        "\n",
        "def get_resource_sets(sample_size = None):\n",
        "    \"\"\"\n",
        "    Generates and returns the resource sets for all students\n",
        "    \"\"\"\n",
        "    global student_vle_df\n",
        "    global student_assessment_df\n",
        "\n",
        "    resource_sets = []\n",
        "\n",
        "    SAMPLE_SIZE = sample_size if sample_size is not None else student_info_df.shape[0]\n",
        "    for index, student in tqdm(student_info_df.sample(n=SAMPLE_SIZE, random_state=1).iterrows(), total=SAMPLE_SIZE, desc=\"Processing Students\"):\n",
        "        student_resource_set = get_resource_sets_per_student(student[\"id_student\"])\n",
        "        resource_sets.extend(student_resource_set)\n",
        "    return resource_sets\n",
        "\n",
        "def write_sets_to_file(file_name: str, resource_sets):\n",
        "    with open(file_name, 'w') as f:\n",
        "        for item in resource_sets:\n",
        "            for i in item:\n",
        "                f.write(\"%s \" % i)\n",
        "            f.write(\"\\n\")\n",
        "\n",
        "def get_resource_sets_from_file(file_name):\n",
        "    \"\"\"\n",
        "    Reads the resource sets from a file\n",
        "    \"\"\"\n",
        "    with open(file_name, 'r') as f:\n",
        "        resource_sets = []\n",
        "        for line in f:\n",
        "            resource_set = line.split(\" \")\n",
        "            resource_set.pop(-1)\n",
        "            resource_set = [int(resource) for resource in resource_set]\n",
        "            resource_sets.append(resource_set)\n",
        "        return resource_sets\n",
        "\n",
        "\n",
        "# get_resource_sets_per_student(student_info_df.sample(n=1, random_state=1).iloc[0][\"id_student\"])\n",
        "get_resource_sets(sample_size=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VpgYO2n37l7b"
      },
      "source": [
        "Observation:\n",
        "\n",
        "Currently I get itemsets such that a resource is considered for all assessments after it. This results in really long transaction sets. This results in really long and a lot of itemsets. This also skews support metrics in favor of resources that are perhaps used early on in the course. This is not semantically correct."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "Ub7oU8x17l7b"
      },
      "outputs": [],
      "source": [
        "from mlxtend.preprocessing import TransactionEncoder\n",
        "from mlxtend.frequent_patterns import fpgrowth\n",
        "from mlxtend.frequent_patterns import fpmax, association_rules\n",
        "\"\"\"\n",
        "    Association Analysis using mlxtend and FP Growth\n",
        "\"\"\"\n",
        "\n",
        "# ! This is conventional association analysis. We need to encode for sequential mining\n",
        "\n",
        "def generate_rules(resource_sets):\n",
        "    print(len(resource_sets))\n",
        "    te = TransactionEncoder()\n",
        "    te.fit(resource_sets)\n",
        "    resource_sets_encoded = te.transform(resource_sets)\n",
        "    df = pd.DataFrame(resource_sets_encoded, columns=te.columns_)\n",
        "    df.head()\n",
        "\n",
        "    # fpgrowth finds all frequent itemsets\n",
        "    frequent_itemsets = fpgrowth(df, min_support=0.6, use_colnames=True)\n",
        "\n",
        "    # fpmax finds only maximal frequent itemsets\n",
        "    maximal_itemsets = fpmax(df, min_support=0.10, use_colnames=True)\n",
        "\n",
        "    rules = association_rules(frequent_itemsets, num_itemsets = frequent_itemsets.shape[0],metric=\"confidence\", min_threshold=0.7)\n",
        "    return rules\n",
        "\n",
        "\n",
        "# TODO Filter itemsets by score\n",
        "# TODO print out the supports for each of the items\n",
        "# TODO Account for skewed support distribution\n",
        "# TODO see if you can generate closed\n",
        "# TODO See if a boolean value for 'if' the score went up\n",
        "\n",
        "# with open('data/resource_sets.txt', 'w') as f:\n",
        "    # for item in resource_sets:\n",
        "        # for i in item:\n",
        "            # f.write(\"%s \" % i)\n",
        "        # f.write(\"\\n\")\n",
        "    # f.flush()\n",
        "# generate_rules(resource_sets)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dq-u9hui7l7b"
      },
      "source": [
        "### Sequential Analysis\n",
        "---\n",
        "TODO Sequential algorithms sometimes consider A, B, C and A, B as different. So try turnign the flag off"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "fF3RsH9K7l7c"
      },
      "outputs": [],
      "source": [
        "# from spmf import Spmf\n",
        "#\n",
        "# sp = Spmf(\"PrefixSpan\", input_direct=\"data/resource_sets.txt\", output_filename=\"output.txt\", arguments=[0.1], spmf_bin_location_dir=\"data\")\n",
        "# sp.run()\n",
        "# results = sp.to_pandas_dataframe()\n",
        "# print(results)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "RM5k8Yw_7l7c"
      },
      "outputs": [],
      "source": [
        "# from prefixspan import PrefixSpan\n",
        "#\n",
        "# ps = PrefixSpan(resource_sets)\n",
        "# ps.frequent(10, closed=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_XYPcfr37l7c"
      },
      "source": [
        "## Neural Netowrks\n",
        "\n",
        "We are going to try sequential mining with Neural Networks. RNNs, LSTMs, and then transformers. These models have memory states that would be useful for remembering sequential data and capturing patterns in resources that lead to good results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "LlI2BGo37l7c"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Dense, LSTM, Reshape\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from mlxtend.preprocessing import TransactionEncoder\n",
        "# from keras.preprocessing.text import Tokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MSdaxnyX7l7c"
      },
      "source": [
        "### Preprocessing: LSTMs\n",
        "---\n",
        "\n",
        "- A 'Timestep' is one session before a test. We are only considering 50 resources.\n",
        "- <b>Question</b> This leads to the issue of ignoring early resources in the grand scheme of things. However, I am going off examples of LSTMs in recommender systems where each recommendation system uses items of the same semantic significance. The difference in our case is that Scores and IDs are separate. I am going to try both."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "Ayf18lXL7l7c"
      },
      "outputs": [],
      "source": [
        "# Prepare data for LSTM\n",
        "\n",
        "# resources_sets = get_resource_sets()\n",
        "# resources_sets = get_resource_sets_from_file(\"data/resource_sets.txt\")\n",
        "# print(len(resources_sets))\n",
        "\n",
        "MAX_LEN = 10\n",
        "\n",
        "# plot the number of resources in each set\n",
        "def plot_resource_set_lengths(sets):\n",
        "    lengths = []\n",
        "    for resource_set in sets:\n",
        "        lengths.append(len(resource_set))\n",
        "    sns.scatterplot(x=range(len(lengths)), y=lengths)\n",
        "\n",
        "# plot_resource_set_lengths(resources_sets)\n",
        "\n",
        "def pad_resource_sets(resource_sets):\n",
        "    \"\"\"\n",
        "    Pads the resource sets\n",
        "    \"\"\"\n",
        "    return pad_sequences(resource_sets, padding='pre', truncating='pre', maxlen=MAX_LEN)\n",
        "\n",
        "def tokenize_resource_sets(resource_sets):\n",
        "    \"\"\"\n",
        "    Tokenizes the resource sets\n",
        "    \"\"\"\n",
        "    pass\n",
        "\n",
        "def get_sets_labels(padded_resource_sets):\n",
        "    \"\"\"\n",
        "    Returns the sets and labels\n",
        "    \"\"\"\n",
        "    sets = padded_resource_sets[:, :-1]\n",
        "    labels = padded_resource_sets[:, -1]\n",
        "    return sets, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "2Q-YYsYcFeNZ"
      },
      "outputs": [],
      "source": [
        "def get_filtered_student_resources(student_id):\n",
        "    student_resource_set = get_resource_sets_per_student(student_id)\n",
        "\n",
        "    index = 0\n",
        "    while (index < len(student_resource_set)):\n",
        "        # remove any transaction with the final result less than 85\n",
        "        if (student_resource_set[index][-1] < 85):\n",
        "            student_resource_set.pop(index)\n",
        "        else:\n",
        "            index += 1\n",
        "\n",
        "\n",
        "    return student_resource_set\n",
        "\n",
        "def get_resource_df(student_vle_df, student_info_df, vle_df, sample_size=100):\n",
        "    \"\"\"\n",
        "        Create a Dataframe for training the LSTM. The Dataframe should contains\n",
        "        a sequence of resources used by sucessful students before a test with a successful outcome.\n",
        "    \"\"\"\n",
        "    successful_students_df = get_successful_student_trends(student_info_df.sample(n=sample_size))\n",
        "\n",
        "    unique_vle_resources = vle_df[\"id_site\"].unique()\n",
        "    vocab_size = vle_df[\"id_site\"].unique().shape[0]\n",
        "\n",
        "    # Create a mapping from resource id to index\n",
        "    resource_mapping = {}\n",
        "    inverse_resource_mapping = {}\n",
        "    for index, resource in enumerate(unique_vle_resources):\n",
        "        resource_mapping[resource] = index\n",
        "        inverse_resource_mapping[index] = resource\n",
        "\n",
        "    # Add a mapping for the padding index\n",
        "    resource_mapping[0] = 0\n",
        "    inverse_resource_mapping[0] = 0\n",
        "\n",
        "    vectorized_map = np.vectorize(resource_mapping.get)\n",
        "\n",
        "\n",
        "    vle_df = pd.get_dummies(vle_df, columns=[\"code_module\", \"code_presentation\"])\n",
        "    student_info_df = student_info_df.drop(columns=[\"code_module\", \"code_presentation\"])\n",
        "    resource_sequences = []\n",
        "    # For each student fetch resources used before a test filter\n",
        "    for index, student in tqdm(successful_students_df.iterrows(), total=successful_students_df.shape[0], desc=\"Encoding student resources\"):\n",
        "        student_id = student[\"id_student\"]\n",
        "        student_resource_set = get_filtered_student_resources(student_id)\n",
        "        if (len(student_resource_set) == 0):\n",
        "            continue\n",
        "\n",
        "        padded_student_resource_set = pad_resource_sets(student_resource_set)\n",
        "        # Convert the resource set to a sequence of indices\n",
        "\n",
        "        mapped_resource_sets = []\n",
        "        for list_resources in padded_student_resource_set:\n",
        "            resource_set = vectorized_map(list_resources[:-1])\n",
        "            resource_set_encoded = to_categorical(resource_set, num_classes=vocab_size)\n",
        "            temp_resource_set_encoded = []\n",
        "\n",
        "            # get resource features from the vle based on resource id in list_resources\n",
        "            for index, resource in enumerate(resource_set[:-1]):\n",
        "                if inverse_resource_mapping[resource] != 0 and inverse_resource_mapping[resource]  not in unique_vle_resources:\n",
        "                    print(inverse_resource_mapping[resource])\n",
        "                    print(\"Resource not found in vle_df\")\n",
        "                    continue\n",
        "\n",
        "                if (inverse_resource_mapping[resource] == 0):\n",
        "                    # append a vector of zeros\n",
        "                    resource_encoded = np.zeros(vocab_size + vle_df.shape[1] + student_info_df.shape[1] - 2) # minus 2 for the id_site and student_id columns\n",
        "                    temp_resource_set_encoded.append(resource_encoded)\n",
        "                    continue\n",
        "\n",
        "                resource_df = vle_df[vle_df['id_site'] == inverse_resource_mapping[resource]]\n",
        "                student_df = student_info_df[student_info_df['id_student'] == student_id]\n",
        "\n",
        "                # We can add richer information based on student scores to these resources\n",
        "                # However, we have already filtered these sequences to only include successful students\n",
        "\n",
        "                # append resource_df and student_df to resource in temp_resource_set_encoded\n",
        "                resource_encoded = resource_set_encoded[index].tolist()\n",
        "                resource_encoded.extend(resource_df.iloc[0, 1:].values)\n",
        "                resource_encoded.extend(student_df.iloc[0, 1:].values)\n",
        "                temp_resource_set_encoded.append(np.array(resource_encoded))\n",
        "\n",
        "            resource_set = np.array(temp_resource_set_encoded)\n",
        "            if len(resource_set) == 0:\n",
        "                continue\n",
        "\n",
        "            mapped_resource_sets.append(resource_set)\n",
        "        resource_sequences.extend(mapped_resource_sets)\n",
        "\n",
        "\n",
        "    # separate the features and labels\n",
        "    resource_sequences = np.array(resource_sequences)\n",
        "    x = resource_sequences[:, :-1]\n",
        "    y = resource_sequences[:, -1]\n",
        "\n",
        "    # strip all resources in y of the student and resource features\n",
        "    y = y[:, :vocab_size]\n",
        "\n",
        "    return x, y\n",
        "\n",
        "# get_resource_df(student_vle_df, student_info_df, vle_df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "g3WNQC2BFeNZ",
        "outputId": "f31ea0b5-04b7-4d8b-9c01-ad77f7dda112"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Students: 100%|██████████| 10000/10000 [00:18<00:00, 530.92it/s]\n",
            "Encoding student resources: 100%|██████████| 1576/1576 [01:13<00:00, 21.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5015, 7, 6421)\n",
            "(5015, 6364)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/wrapper.py:27: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - accuracy: 0.0077 - loss: 8.0229 - mae: 0.2106 - val_accuracy: 0.0110 - val_loss: 7.3602 - val_mae: 0.0189\n",
            "Epoch 2/20\n",
            "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.0116 - loss: 6.5439 - mae: 0.0188 - val_accuracy: 0.0179 - val_loss: 7.1153 - val_mae: 0.0218\n",
            "Epoch 3/20\n",
            "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.0110 - loss: 6.2705 - mae: 0.0214 - val_accuracy: 0.0179 - val_loss: 7.1633 - val_mae: 0.0185\n",
            "Epoch 4/20\n",
            "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.0103 - loss: 6.0830 - mae: 0.0216 - val_accuracy: 0.0120 - val_loss: 7.1438 - val_mae: 0.0215\n",
            "Epoch 5/20\n",
            "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.0128 - loss: 5.9341 - mae: 0.0236 - val_accuracy: 0.0140 - val_loss: 7.0157 - val_mae: 0.0243\n",
            "Epoch 6/20\n",
            "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.0355 - loss: 5.7203 - mae: 0.0231 - val_accuracy: 0.0179 - val_loss: 6.9637 - val_mae: 0.0236\n",
            "Epoch 7/20\n",
            "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.0318 - loss: 5.5511 - mae: 0.0229 - val_accuracy: 0.0379 - val_loss: 7.0134 - val_mae: 0.0207\n",
            "Epoch 8/20\n",
            "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.0454 - loss: 5.3329 - mae: 0.0223 - val_accuracy: 0.0349 - val_loss: 6.9532 - val_mae: 0.0197\n",
            "Epoch 9/20\n",
            "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.0506 - loss: 5.2274 - mae: 0.0224 - val_accuracy: 0.0399 - val_loss: 6.8836 - val_mae: 0.0210\n",
            "Epoch 10/20\n",
            "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.0605 - loss: 4.9918 - mae: 0.0217 - val_accuracy: 0.0359 - val_loss: 6.7893 - val_mae: 0.0223\n",
            "Epoch 11/20\n",
            "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.0753 - loss: 4.8191 - mae: 0.0215 - val_accuracy: 0.0299 - val_loss: 6.7009 - val_mae: 0.0260\n",
            "Epoch 12/20\n",
            "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.0811 - loss: 4.7417 - mae: 0.0216 - val_accuracy: 0.0449 - val_loss: 6.7656 - val_mae: 0.0214\n",
            "Epoch 13/20\n",
            "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.0946 - loss: 4.5514 - mae: 0.0209 - val_accuracy: 0.0618 - val_loss: 6.7226 - val_mae: 0.0198\n",
            "Epoch 14/20\n",
            "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.1060 - loss: 4.4357 - mae: 0.0203 - val_accuracy: 0.0708 - val_loss: 6.6987 - val_mae: 0.0188\n",
            "Epoch 15/20\n",
            "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.1278 - loss: 4.2592 - mae: 0.0188 - val_accuracy: 0.0608 - val_loss: 6.6768 - val_mae: 0.0184\n",
            "Epoch 16/20\n",
            "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.1385 - loss: 4.1264 - mae: 0.0183 - val_accuracy: 0.0708 - val_loss: 6.6874 - val_mae: 0.0162\n",
            "Epoch 17/20\n",
            "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.1490 - loss: 4.0106 - mae: 0.0176 - val_accuracy: 0.0748 - val_loss: 6.6071 - val_mae: 0.0165\n",
            "Epoch 18/20\n",
            "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.1637 - loss: 3.9117 - mae: 0.0170 - val_accuracy: 0.0758 - val_loss: 6.5802 - val_mae: 0.0163\n",
            "Epoch 19/20\n",
            "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.1860 - loss: 3.7858 - mae: 0.0158 - val_accuracy: 0.0907 - val_loss: 6.5903 - val_mae: 0.0149\n",
            "Epoch 20/20\n",
            "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.1992 - loss: 3.6512 - mae: 0.0148 - val_accuracy: 0.0927 - val_loss: 6.5358 - val_mae: 0.0134\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Dropout, Dense, LSTM, Reshape, TimeDistributed, Input\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from time import time\n",
        "\n",
        "gpu_devices = tf.config.list_physical_devices('GPU')\n",
        "print(gpu_devices)\n",
        "\n",
        "x, y = get_resource_df(student_vle_df, student_info_df, vle_df, sample_size=student_info_df.shape[0])\n",
        "print(x.shape)\n",
        "print(y.shape)\n",
        "model = Sequential()\n",
        "model.add(TimeDistributed(Dense(256, activation='relu'), input_shape=(7, 6421))) # TODO Try adding an Embedding layer and removing the other features\n",
        "model.add(LSTM(128))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(6364, activation='sigmoid'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy', 'mae'])\n",
        "\n",
        "h = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2)\n",
        "plt.figure()\n",
        "plt.plot(h.history['loss'], label='Train loss')\n",
        "plt.plot(h.history['val_loss'], label='Validation loss')\n",
        "plt.legend()\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "# save the plot as a png file named as loss_datetime.png\n",
        "plt.savefig(f\"graphs/loss_{datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}.png\")\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(h.history['accuracy'], label='Train accuracy')\n",
        "plt.plot(h.history['val_accuracy'], label='Validation accuracy')\n",
        "plt.legend()\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.savefig(f\"graphs/accuracy_{datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}.png\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x, y = get_resource_df(student_vle_df, student_info_df, vle_df, sample_size=5000)\n",
        "x, x_test, y, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "# Convert to PyTorch tensors\n",
        "x = torch.tensor(x, dtype=torch.float32)  # (batch, seq, num_resources + meta_dim)\n",
        "y = torch.tensor(y, dtype=torch.float32)  # (batch, num_resources)\n",
        "\n",
        "x_test = torch.tensor(x_test, dtype=torch.float32)  # (batch, seq, num_resources + meta_dim)\n",
        "y_test = torch.tensor(y_test, dtype=torch.float32)"
      ],
      "metadata": {
        "id": "Fc6x9WUne6BA",
        "outputId": "60f9018f-a3aa-47b7-8d93-9072b74d7a3f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Students: 100%|██████████| 5000/5000 [00:09<00:00, 529.63it/s]\n",
            "Encoding student resources: 100%|██████████| 764/764 [00:36<00:00, 20.69it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F8V-01dDFeNa",
        "outputId": "71930275-dc9e-48a0-8ede-bf5a72458bc0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2466, 7, 6364])\n",
            "torch.Size([2466, 7, 57])\n",
            "Loss: 0.6973896622657776\n",
            "tensor([[5561],\n",
            "        [2042],\n",
            "        [5587],\n",
            "        ...,\n",
            "        [1885],\n",
            "        [1885],\n",
            "        [1885]])\n",
            "tensor([[6224],\n",
            "        [6207],\n",
            "        [6145],\n",
            "        ...,\n",
            "        [4731],\n",
            "        [5008],\n",
            "        [4661]])\n",
            "Accuracy: 0.0\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "# Hyperparams\n",
        "num_resources = 6364\n",
        "meta_dim = 57\n",
        "embed_dim = 128\n",
        "meta_out_dim = 32\n",
        "lstm_hidden_dim = 128\n",
        "seq_len = 7\n",
        "\n",
        "\n",
        "\n",
        "# Split input into resource IDs and metadata\n",
        "resource_onehot = torch.tensor(x[:, :, :num_resources], dtype=torch.float32)       # (batch, seq, 6436)\n",
        "print(resource_onehot.shape)\n",
        "metadata = torch.tensor(x[:, :, num_resources:], dtype=torch.float32)              # (batch, seq, 57)\n",
        "print(metadata.shape)\n",
        "resource_ids = torch.argmax(resource_onehot, dim=-1)  # (batch, seq)\n",
        "\n",
        "# Define layers\n",
        "resource_embedding = nn.Embedding(num_resources, embed_dim)\n",
        "metadata_dense = nn.Linear(meta_dim, meta_out_dim)\n",
        "lstm = nn.LSTM(input_size=embed_dim + meta_out_dim, hidden_size=lstm_hidden_dim, batch_first=True)\n",
        "output_layer = nn.Linear(lstm_hidden_dim, num_resources)\n",
        "\n",
        "# Forward pass\n",
        "resource_embed = resource_embedding(resource_ids)                   # (batch, seq, embed_dim)\n",
        "metadata_embed = F.relu(metadata_dense(metadata))                  # (batch, seq, meta_out_dim)\n",
        "lstm_input = torch.cat([resource_embed, metadata_embed], dim=-1)   # (batch, seq, embed + meta)\n",
        "\n",
        "lstm_out, _ = lstm(lstm_input)             # (batch, seq, hidden_dim)\n",
        "final_output = lstm_out[:, -1, :]          # (batch, hidden_dim)\n",
        "pred = torch.sigmoid(output_layer(final_output))  # (batch, 6436)\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = torch.optim.Adam([\n",
        "    *resource_embedding.parameters(),\n",
        "    *metadata_dense.parameters(),\n",
        "    *lstm.parameters(),\n",
        "    *output_layer.parameters()\n",
        "], lr=0.001)\n",
        "\n",
        "loss = criterion(pred, torch.tensor(y, dtype=torch.float32))\n",
        "optimizer.zero_grad()\n",
        "loss.backward()\n",
        "optimizer.step()\n",
        "\n",
        "print(\"Loss:\", loss.item())\n",
        "\n",
        "# test accuracy\n",
        "with torch.no_grad():\n",
        "    pred = torch.sigmoid(output_layer(lstm_out[:, -1, :]))\n",
        "    predicted = torch.topk(pred, k=1, dim=-1).indices\n",
        "    print(predicted)\n",
        "    y = torch.topk(torch.tensor(y, dtype=torch.float32), k=1, dim=-1).indices\n",
        "    print(y)\n",
        "    correct = (predicted == y).float().sum()\n",
        "    accuracy = correct / y.shape[0]\n",
        "    print(f\"Accuracy: {accuracy}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run inference\n",
        "with torch.no_grad():\n",
        "    pred = torch.sigmoid(output_layer(lstm_out[:, -1, :]))\n",
        "    top_preds = torch.topk(pred, k=5, dim=-1)\n",
        "    print(\"Top 5 predictions:\", top_preds.indices)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vrieJXj0Jy0g",
        "outputId": "73ca7921-7b5e-4feb-c700-31aaf1f2c23f"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 5 predictions: tensor([[2681, 2120,  634,  328, 1512],\n",
            "        [2681, 2030, 3330, 1512,  634],\n",
            "        [3330, 5142, 2681, 5969,  328],\n",
            "        ...,\n",
            "        [2681,  634, 2776, 1512, 5428],\n",
            "        [2681,  328, 1027, 5481, 5067],\n",
            "        [2681,  527, 5142, 3466, 3330]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t3zo4XMHFeNa"
      },
      "source": [
        "# Class Implementation of a pytorch LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "FS_nXsOpFeNb"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "v-uERVcsFeNc"
      },
      "outputs": [],
      "source": [
        "class Predictor(nn.Module):\n",
        "  NUM_RESOURCES = 6364\n",
        "  META_DIM = 57\n",
        "  EMBED_DIM = 128\n",
        "  META_OUT_DIM = 32\n",
        "  LSTM_HIDDEN_DIM = 128\n",
        "  SEQ_LEN = 7\n",
        "  def __init__(self, num_resources = NUM_RESOURCES, meta_dim = META_DIM,\n",
        "               embed_dim = EMBED_DIM, meta_out_dim = META_OUT_DIM, lstm_hidden_dim = LSTM_HIDDEN_DIM):\n",
        "    super(Predictor, self).__init__()\n",
        "    self.num_resources = num_resources\n",
        "    self.meta_dim = meta_dim\n",
        "\n",
        "    weights = torch.rand(num_resources, embed_dim)\n",
        "\n",
        "    self.resource_embedding = nn.Embedding(num_resources, embed_dim, _weight=weights)\n",
        "    self.metadata_dense = nn.Linear(meta_dim, meta_out_dim)\n",
        "    self.lstm = nn.LSTM(input_size=embed_dim + meta_out_dim, hidden_size=lstm_hidden_dim, batch_first=True)\n",
        "    self.output_layer = nn.Linear(lstm_hidden_dim, num_resources)\n",
        "\n",
        "  def forward(self, x):\n",
        "    resource_onehot = x[:, :, :self.num_resources]\n",
        "    metadata = x[:, :, self.num_resources:]\n",
        "    resource_ids = torch.argmax(resource_onehot, dim=-1)\n",
        "    resource_embeds = self.resource_embedding(resource_ids)\n",
        "    metadata_encoded = F.relu(self.metadata_dense(metadata))\n",
        "    lstm_input = torch.cat([resource_embeds, metadata_encoded], dim=-1)\n",
        "    lstm_out, _ = self.lstm(lstm_input)\n",
        "    final_hidden = lstm_out[:, -1, :]\n",
        "    pred = torch.sigmoid(self.output_layer(final_hidden))\n",
        "    return pred"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, dataloader, loss_fn):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    total_acc = 0\n",
        "    total_samples = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x_batch, y_batch in dataloader:\n",
        "            preds = model.forward(x_batch)\n",
        "            loss = loss_fn(preds, y_batch)\n",
        "\n",
        "            total_loss += loss.item() * x_batch.size(0)\n",
        "\n",
        "            top_k_preds = torch.topk(preds, k=1, dim=-1).indices\n",
        "            y_batch = torch.topk(y_batch, k=1, dim=-1).indices\n",
        "            print(top_k_preds)\n",
        "            print(y_batch)\n",
        "            # Binary accuracy (threshold 0.5)\n",
        "            predicted = (preds > 0.5).float()\n",
        "            correct = (predicted == y_batch).float().sum()\n",
        "            total_acc += correct\n",
        "            total_samples += y_batch.numel()\n",
        "\n",
        "    avg_loss = total_loss / len(dataloader.dataset)\n",
        "    avg_acc = total_acc / total_samples\n",
        "    print(f\"Evaluation — Loss: {avg_loss:.4f}, Accuracy: {avg_acc:.4f}\")\n",
        "    return avg_loss, avg_acc\n"
      ],
      "metadata": {
        "id": "odJiaY_vNK0t"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x, y = get_resource_df(student_vle_df, student_info_df, vle_df, sample_size=1000)\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
        "\n",
        "x, x_val, y, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n",
        "x = torch.tensor(x, dtype=torch.float32)\n",
        "y = torch.tensor(y, dtype=torch.float32)\n",
        "\n",
        "x_test = torch.tensor(x_test, dtype=torch.float32)\n",
        "y_test = torch.tensor(y_test, dtype=torch.float32)\n",
        "\n",
        "x_val = torch.tensor(x_val, dtype=torch.float32)\n",
        "y_val = torch.tensor(y_val, dtype=torch.float32)\n",
        "\n",
        "train_loader = DataLoader(TensorDataset(x, y), batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(TensorDataset(x_test, y_test), batch_size=32)\n",
        "val_loader = DataLoader(TensorDataset(x_val, y_val), batch_size = 32)"
      ],
      "metadata": {
        "id": "VM4edEdTcYnI",
        "outputId": "0a2038ce-02d0-4cf7-b847-549a246f7987",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Students: 100%|██████████| 1000/1000 [00:01<00:00, 528.16it/s]\n",
            "Encoding student resources: 100%|██████████| 144/144 [00:07<00:00, 20.32it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "model = Predictor()\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "train_losses, val_losses, val_accuracies = [], [], []\n",
        "\n",
        "NUM_EPOCHS = 20\n",
        "for epoch in range(20):\n",
        "  print(f\"Epoch: {epoch}\")\n",
        "\n",
        "  loss = 0\n",
        "  for x_batch, y_batch in train_loader:\n",
        "    optimizer.zero_grad()\n",
        "    preds = model(x_batch)\n",
        "    loss = criterion(preds, y_batch)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    loss += loss.item()\n",
        "\n",
        "  val_loss, val_acc = evaluate_model(model, val_loader, criterion)\n",
        "  train_losses.append(loss / len(train_loader))\n",
        "  val_losses.append(val_loss)\n",
        "  val_accuracies.append(val_acc)\n",
        "  print(f\"Epoch {epoch+1} — Train Loss: {train_losses[-1]:.4f}, Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "PPfxygngL8rP",
        "outputId": "695e54af-effe-4296-b1aa-adc791504a2d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0\n",
            "tensor([[5640],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [5640],\n",
            "        [6159],\n",
            "        [3171],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [3171],\n",
            "        [5640],\n",
            "        [6159],\n",
            "        [3171],\n",
            "        [6159],\n",
            "        [5640],\n",
            "        [ 124],\n",
            "        [3171],\n",
            "        [5640],\n",
            "        [6159],\n",
            "        [5640],\n",
            "        [3171],\n",
            "        [5640],\n",
            "        [5640],\n",
            "        [3171],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [5640],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159]])\n",
            "tensor([[6092],\n",
            "        [1243],\n",
            "        [ 640],\n",
            "        [4789],\n",
            "        [5163],\n",
            "        [6184],\n",
            "        [2038],\n",
            "        [6250],\n",
            "        [5596],\n",
            "        [4641],\n",
            "        [6097],\n",
            "        [6007],\n",
            "        [1009],\n",
            "        [6027],\n",
            "        [4613],\n",
            "        [6023],\n",
            "        [6283],\n",
            "        [6013],\n",
            "        [1363],\n",
            "        [1635],\n",
            "        [5672],\n",
            "        [5997],\n",
            "        [6231],\n",
            "        [6023],\n",
            "        [6286],\n",
            "        [1172],\n",
            "        [ 522],\n",
            "        [6172],\n",
            "        [5289],\n",
            "        [5793],\n",
            "        [4673],\n",
            "        [5930]])\n",
            "tensor([[6159],\n",
            "        [5640],\n",
            "        [3171],\n",
            "        [6029],\n",
            "        [6159],\n",
            "        [3171],\n",
            "        [5640],\n",
            "        [3171],\n",
            "        [6159],\n",
            "        [5640],\n",
            "        [3171],\n",
            "        [5640],\n",
            "        [ 124],\n",
            "        [5640],\n",
            "        [3171],\n",
            "        [5640],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [5640],\n",
            "        [3171],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [5640],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [5640],\n",
            "        [5640],\n",
            "        [5640]])\n",
            "tensor([[6068],\n",
            "        [6274],\n",
            "        [6342],\n",
            "        [4512],\n",
            "        [ 788],\n",
            "        [6227],\n",
            "        [ 623],\n",
            "        [6088],\n",
            "        [5852],\n",
            "        [1747],\n",
            "        [6329],\n",
            "        [3754],\n",
            "        [6349],\n",
            "        [3828],\n",
            "        [6325],\n",
            "        [5672],\n",
            "        [3945],\n",
            "        [2157],\n",
            "        [4353],\n",
            "        [5100],\n",
            "        [6277],\n",
            "        [2396],\n",
            "        [1243],\n",
            "        [ 709],\n",
            "        [ 623],\n",
            "        [4192],\n",
            "        [ 766],\n",
            "        [1147],\n",
            "        [4522],\n",
            "        [6342],\n",
            "        [6027],\n",
            "        [6280]])\n",
            "tensor([[5640],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [5640],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [5640],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [5640]])\n",
            "tensor([[6328],\n",
            "        [ 539],\n",
            "        [ 672],\n",
            "        [6101],\n",
            "        [4492],\n",
            "        [ 601],\n",
            "        [4872],\n",
            "        [1274],\n",
            "        [1393],\n",
            "        [6284],\n",
            "        [1152],\n",
            "        [4673],\n",
            "        [3519],\n",
            "        [6023]])\n",
            "Evaluation — Loss: 0.3803, Accuracy: 0.0000\n",
            "Epoch 1 — Train Loss: 0.0849, Val Loss: 0.3803, Val Acc: 0.0000\n",
            "Epoch: 1\n",
            "tensor([[3171],\n",
            "        [3171],\n",
            "        [3171],\n",
            "        [6159],\n",
            "        [3171],\n",
            "        [6159],\n",
            "        [3171],\n",
            "        [3171],\n",
            "        [3171],\n",
            "        [3171],\n",
            "        [3171],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [3171],\n",
            "        [3171],\n",
            "        [3171],\n",
            "        [3171],\n",
            "        [3171],\n",
            "        [3171],\n",
            "        [6159],\n",
            "        [3171],\n",
            "        [3171],\n",
            "        [6159],\n",
            "        [3171],\n",
            "        [3171],\n",
            "        [3171],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [3171],\n",
            "        [3171],\n",
            "        [3171],\n",
            "        [3171]])\n",
            "tensor([[6092],\n",
            "        [1243],\n",
            "        [ 640],\n",
            "        [4789],\n",
            "        [5163],\n",
            "        [6184],\n",
            "        [2038],\n",
            "        [6250],\n",
            "        [5596],\n",
            "        [4641],\n",
            "        [6097],\n",
            "        [6007],\n",
            "        [1009],\n",
            "        [6027],\n",
            "        [4613],\n",
            "        [6023],\n",
            "        [6283],\n",
            "        [6013],\n",
            "        [1363],\n",
            "        [1635],\n",
            "        [5672],\n",
            "        [5997],\n",
            "        [6231],\n",
            "        [6023],\n",
            "        [6286],\n",
            "        [1172],\n",
            "        [ 522],\n",
            "        [6172],\n",
            "        [5289],\n",
            "        [5793],\n",
            "        [4673],\n",
            "        [5930]])\n",
            "tensor([[3171],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [3171],\n",
            "        [3171],\n",
            "        [3171],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [3171],\n",
            "        [6159],\n",
            "        [3171],\n",
            "        [3171],\n",
            "        [3171],\n",
            "        [6159],\n",
            "        [3171],\n",
            "        [3171],\n",
            "        [3171],\n",
            "        [3171],\n",
            "        [3171],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [3171],\n",
            "        [3171],\n",
            "        [3171],\n",
            "        [3171],\n",
            "        [6159],\n",
            "        [3171],\n",
            "        [6159]])\n",
            "tensor([[6068],\n",
            "        [6274],\n",
            "        [6342],\n",
            "        [4512],\n",
            "        [ 788],\n",
            "        [6227],\n",
            "        [ 623],\n",
            "        [6088],\n",
            "        [5852],\n",
            "        [1747],\n",
            "        [6329],\n",
            "        [3754],\n",
            "        [6349],\n",
            "        [3828],\n",
            "        [6325],\n",
            "        [5672],\n",
            "        [3945],\n",
            "        [2157],\n",
            "        [4353],\n",
            "        [5100],\n",
            "        [6277],\n",
            "        [2396],\n",
            "        [1243],\n",
            "        [ 709],\n",
            "        [ 623],\n",
            "        [4192],\n",
            "        [ 766],\n",
            "        [1147],\n",
            "        [4522],\n",
            "        [6342],\n",
            "        [6027],\n",
            "        [6280]])\n",
            "tensor([[3171],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [3171],\n",
            "        [3171],\n",
            "        [6159],\n",
            "        [3171],\n",
            "        [6159],\n",
            "        [3171],\n",
            "        [6159],\n",
            "        [3171],\n",
            "        [3171],\n",
            "        [3171],\n",
            "        [6159]])\n",
            "tensor([[6328],\n",
            "        [ 539],\n",
            "        [ 672],\n",
            "        [6101],\n",
            "        [4492],\n",
            "        [ 601],\n",
            "        [4872],\n",
            "        [1274],\n",
            "        [1393],\n",
            "        [6284],\n",
            "        [1152],\n",
            "        [4673],\n",
            "        [3519],\n",
            "        [6023]])\n",
            "Evaluation — Loss: 0.0986, Accuracy: 0.0000\n",
            "Epoch 2 — Train Loss: 0.0224, Val Loss: 0.0986, Val Acc: 0.0000\n",
            "Epoch: 2\n",
            "tensor([[3171],\n",
            "        [3171],\n",
            "        [3171],\n",
            "        [3171],\n",
            "        [3171],\n",
            "        [6159],\n",
            "        [3171],\n",
            "        [3171],\n",
            "        [3171],\n",
            "        [3171],\n",
            "        [3171],\n",
            "        [6159],\n",
            "        [3171],\n",
            "        [3171],\n",
            "        [3171],\n",
            "        [3171],\n",
            "        [3171],\n",
            "        [3171],\n",
            "        [3171],\n",
            "        [3171],\n",
            "        [3171],\n",
            "        [3171],\n",
            "        [3171],\n",
            "        [3171],\n",
            "        [3171],\n",
            "        [3171],\n",
            "        [3171],\n",
            "        [6159],\n",
            "        [3171],\n",
            "        [3171],\n",
            "        [3171],\n",
            "        [3171]])\n",
            "tensor([[6092],\n",
            "        [1243],\n",
            "        [ 640],\n",
            "        [4789],\n",
            "        [5163],\n",
            "        [6184],\n",
            "        [2038],\n",
            "        [6250],\n",
            "        [5596],\n",
            "        [4641],\n",
            "        [6097],\n",
            "        [6007],\n",
            "        [1009],\n",
            "        [6027],\n",
            "        [4613],\n",
            "        [6023],\n",
            "        [6283],\n",
            "        [6013],\n",
            "        [1363],\n",
            "        [1635],\n",
            "        [5672],\n",
            "        [5997],\n",
            "        [6231],\n",
            "        [6023],\n",
            "        [6286],\n",
            "        [1172],\n",
            "        [ 522],\n",
            "        [6172],\n",
            "        [5289],\n",
            "        [5793],\n",
            "        [4673],\n",
            "        [5930]])\n",
            "tensor([[3171],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [3171],\n",
            "        [3171],\n",
            "        [3171],\n",
            "        [3171],\n",
            "        [3171],\n",
            "        [3171],\n",
            "        [6159],\n",
            "        [3171],\n",
            "        [3171],\n",
            "        [3171],\n",
            "        [3171],\n",
            "        [3171],\n",
            "        [3171],\n",
            "        [3171],\n",
            "        [3171],\n",
            "        [3171],\n",
            "        [3171],\n",
            "        [3171],\n",
            "        [3171],\n",
            "        [3171],\n",
            "        [3171],\n",
            "        [3171],\n",
            "        [3171],\n",
            "        [3171],\n",
            "        [3171],\n",
            "        [3171],\n",
            "        [6159],\n",
            "        [3171],\n",
            "        [3171]])\n",
            "tensor([[6068],\n",
            "        [6274],\n",
            "        [6342],\n",
            "        [4512],\n",
            "        [ 788],\n",
            "        [6227],\n",
            "        [ 623],\n",
            "        [6088],\n",
            "        [5852],\n",
            "        [1747],\n",
            "        [6329],\n",
            "        [3754],\n",
            "        [6349],\n",
            "        [3828],\n",
            "        [6325],\n",
            "        [5672],\n",
            "        [3945],\n",
            "        [2157],\n",
            "        [4353],\n",
            "        [5100],\n",
            "        [6277],\n",
            "        [2396],\n",
            "        [1243],\n",
            "        [ 709],\n",
            "        [ 623],\n",
            "        [4192],\n",
            "        [ 766],\n",
            "        [1147],\n",
            "        [4522],\n",
            "        [6342],\n",
            "        [6027],\n",
            "        [6280]])\n",
            "tensor([[3171],\n",
            "        [3171],\n",
            "        [3171],\n",
            "        [3171],\n",
            "        [3171],\n",
            "        [3171],\n",
            "        [3171],\n",
            "        [3171],\n",
            "        [3171],\n",
            "        [3171],\n",
            "        [3171],\n",
            "        [3171],\n",
            "        [3171],\n",
            "        [3171]])\n",
            "tensor([[6328],\n",
            "        [ 539],\n",
            "        [ 672],\n",
            "        [6101],\n",
            "        [4492],\n",
            "        [ 601],\n",
            "        [4872],\n",
            "        [1274],\n",
            "        [1393],\n",
            "        [6284],\n",
            "        [1152],\n",
            "        [4673],\n",
            "        [3519],\n",
            "        [6023]])\n",
            "Evaluation — Loss: 0.0350, Accuracy: 0.0000\n",
            "Epoch 3 — Train Loss: 0.0076, Val Loss: 0.0350, Val Acc: 0.0000\n",
            "Epoch: 3\n",
            "tensor([[6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159]])\n",
            "tensor([[6092],\n",
            "        [1243],\n",
            "        [ 640],\n",
            "        [4789],\n",
            "        [5163],\n",
            "        [6184],\n",
            "        [2038],\n",
            "        [6250],\n",
            "        [5596],\n",
            "        [4641],\n",
            "        [6097],\n",
            "        [6007],\n",
            "        [1009],\n",
            "        [6027],\n",
            "        [4613],\n",
            "        [6023],\n",
            "        [6283],\n",
            "        [6013],\n",
            "        [1363],\n",
            "        [1635],\n",
            "        [5672],\n",
            "        [5997],\n",
            "        [6231],\n",
            "        [6023],\n",
            "        [6286],\n",
            "        [1172],\n",
            "        [ 522],\n",
            "        [6172],\n",
            "        [5289],\n",
            "        [5793],\n",
            "        [4673],\n",
            "        [5930]])\n",
            "tensor([[6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159]])\n",
            "tensor([[6068],\n",
            "        [6274],\n",
            "        [6342],\n",
            "        [4512],\n",
            "        [ 788],\n",
            "        [6227],\n",
            "        [ 623],\n",
            "        [6088],\n",
            "        [5852],\n",
            "        [1747],\n",
            "        [6329],\n",
            "        [3754],\n",
            "        [6349],\n",
            "        [3828],\n",
            "        [6325],\n",
            "        [5672],\n",
            "        [3945],\n",
            "        [2157],\n",
            "        [4353],\n",
            "        [5100],\n",
            "        [6277],\n",
            "        [2396],\n",
            "        [1243],\n",
            "        [ 709],\n",
            "        [ 623],\n",
            "        [4192],\n",
            "        [ 766],\n",
            "        [1147],\n",
            "        [4522],\n",
            "        [6342],\n",
            "        [6027],\n",
            "        [6280]])\n",
            "tensor([[6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159]])\n",
            "tensor([[6328],\n",
            "        [ 539],\n",
            "        [ 672],\n",
            "        [6101],\n",
            "        [4492],\n",
            "        [ 601],\n",
            "        [4872],\n",
            "        [1274],\n",
            "        [1393],\n",
            "        [6284],\n",
            "        [1152],\n",
            "        [4673],\n",
            "        [3519],\n",
            "        [6023]])\n",
            "Evaluation — Loss: 0.0185, Accuracy: 0.0000\n",
            "Epoch 4 — Train Loss: 0.0039, Val Loss: 0.0185, Val Acc: 0.0000\n",
            "Epoch: 4\n",
            "tensor([[6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159]])\n",
            "tensor([[6092],\n",
            "        [1243],\n",
            "        [ 640],\n",
            "        [4789],\n",
            "        [5163],\n",
            "        [6184],\n",
            "        [2038],\n",
            "        [6250],\n",
            "        [5596],\n",
            "        [4641],\n",
            "        [6097],\n",
            "        [6007],\n",
            "        [1009],\n",
            "        [6027],\n",
            "        [4613],\n",
            "        [6023],\n",
            "        [6283],\n",
            "        [6013],\n",
            "        [1363],\n",
            "        [1635],\n",
            "        [5672],\n",
            "        [5997],\n",
            "        [6231],\n",
            "        [6023],\n",
            "        [6286],\n",
            "        [1172],\n",
            "        [ 522],\n",
            "        [6172],\n",
            "        [5289],\n",
            "        [5793],\n",
            "        [4673],\n",
            "        [5930]])\n",
            "tensor([[6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159]])\n",
            "tensor([[6068],\n",
            "        [6274],\n",
            "        [6342],\n",
            "        [4512],\n",
            "        [ 788],\n",
            "        [6227],\n",
            "        [ 623],\n",
            "        [6088],\n",
            "        [5852],\n",
            "        [1747],\n",
            "        [6329],\n",
            "        [3754],\n",
            "        [6349],\n",
            "        [3828],\n",
            "        [6325],\n",
            "        [5672],\n",
            "        [3945],\n",
            "        [2157],\n",
            "        [4353],\n",
            "        [5100],\n",
            "        [6277],\n",
            "        [2396],\n",
            "        [1243],\n",
            "        [ 709],\n",
            "        [ 623],\n",
            "        [4192],\n",
            "        [ 766],\n",
            "        [1147],\n",
            "        [4522],\n",
            "        [6342],\n",
            "        [6027],\n",
            "        [6280]])\n",
            "tensor([[6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159]])\n",
            "tensor([[6328],\n",
            "        [ 539],\n",
            "        [ 672],\n",
            "        [6101],\n",
            "        [4492],\n",
            "        [ 601],\n",
            "        [4872],\n",
            "        [1274],\n",
            "        [1393],\n",
            "        [6284],\n",
            "        [1152],\n",
            "        [4673],\n",
            "        [3519],\n",
            "        [6023]])\n",
            "Evaluation — Loss: 0.0125, Accuracy: 0.0000\n",
            "Epoch 5 — Train Loss: 0.0026, Val Loss: 0.0125, Val Acc: 0.0000\n",
            "Epoch: 5\n",
            "tensor([[6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159]])\n",
            "tensor([[6092],\n",
            "        [1243],\n",
            "        [ 640],\n",
            "        [4789],\n",
            "        [5163],\n",
            "        [6184],\n",
            "        [2038],\n",
            "        [6250],\n",
            "        [5596],\n",
            "        [4641],\n",
            "        [6097],\n",
            "        [6007],\n",
            "        [1009],\n",
            "        [6027],\n",
            "        [4613],\n",
            "        [6023],\n",
            "        [6283],\n",
            "        [6013],\n",
            "        [1363],\n",
            "        [1635],\n",
            "        [5672],\n",
            "        [5997],\n",
            "        [6231],\n",
            "        [6023],\n",
            "        [6286],\n",
            "        [1172],\n",
            "        [ 522],\n",
            "        [6172],\n",
            "        [5289],\n",
            "        [5793],\n",
            "        [4673],\n",
            "        [5930]])\n",
            "tensor([[6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159]])\n",
            "tensor([[6068],\n",
            "        [6274],\n",
            "        [6342],\n",
            "        [4512],\n",
            "        [ 788],\n",
            "        [6227],\n",
            "        [ 623],\n",
            "        [6088],\n",
            "        [5852],\n",
            "        [1747],\n",
            "        [6329],\n",
            "        [3754],\n",
            "        [6349],\n",
            "        [3828],\n",
            "        [6325],\n",
            "        [5672],\n",
            "        [3945],\n",
            "        [2157],\n",
            "        [4353],\n",
            "        [5100],\n",
            "        [6277],\n",
            "        [2396],\n",
            "        [1243],\n",
            "        [ 709],\n",
            "        [ 623],\n",
            "        [4192],\n",
            "        [ 766],\n",
            "        [1147],\n",
            "        [4522],\n",
            "        [6342],\n",
            "        [6027],\n",
            "        [6280]])\n",
            "tensor([[6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159]])\n",
            "tensor([[6328],\n",
            "        [ 539],\n",
            "        [ 672],\n",
            "        [6101],\n",
            "        [4492],\n",
            "        [ 601],\n",
            "        [4872],\n",
            "        [1274],\n",
            "        [1393],\n",
            "        [6284],\n",
            "        [1152],\n",
            "        [4673],\n",
            "        [3519],\n",
            "        [6023]])\n",
            "Evaluation — Loss: 0.0097, Accuracy: 0.0000\n",
            "Epoch 6 — Train Loss: 0.0020, Val Loss: 0.0097, Val Acc: 0.0000\n",
            "Epoch: 6\n",
            "tensor([[6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159]])\n",
            "tensor([[6092],\n",
            "        [1243],\n",
            "        [ 640],\n",
            "        [4789],\n",
            "        [5163],\n",
            "        [6184],\n",
            "        [2038],\n",
            "        [6250],\n",
            "        [5596],\n",
            "        [4641],\n",
            "        [6097],\n",
            "        [6007],\n",
            "        [1009],\n",
            "        [6027],\n",
            "        [4613],\n",
            "        [6023],\n",
            "        [6283],\n",
            "        [6013],\n",
            "        [1363],\n",
            "        [1635],\n",
            "        [5672],\n",
            "        [5997],\n",
            "        [6231],\n",
            "        [6023],\n",
            "        [6286],\n",
            "        [1172],\n",
            "        [ 522],\n",
            "        [6172],\n",
            "        [5289],\n",
            "        [5793],\n",
            "        [4673],\n",
            "        [5930]])\n",
            "tensor([[6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159]])\n",
            "tensor([[6068],\n",
            "        [6274],\n",
            "        [6342],\n",
            "        [4512],\n",
            "        [ 788],\n",
            "        [6227],\n",
            "        [ 623],\n",
            "        [6088],\n",
            "        [5852],\n",
            "        [1747],\n",
            "        [6329],\n",
            "        [3754],\n",
            "        [6349],\n",
            "        [3828],\n",
            "        [6325],\n",
            "        [5672],\n",
            "        [3945],\n",
            "        [2157],\n",
            "        [4353],\n",
            "        [5100],\n",
            "        [6277],\n",
            "        [2396],\n",
            "        [1243],\n",
            "        [ 709],\n",
            "        [ 623],\n",
            "        [4192],\n",
            "        [ 766],\n",
            "        [1147],\n",
            "        [4522],\n",
            "        [6342],\n",
            "        [6027],\n",
            "        [6280]])\n",
            "tensor([[6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159],\n",
            "        [6159]])\n",
            "tensor([[6328],\n",
            "        [ 539],\n",
            "        [ 672],\n",
            "        [6101],\n",
            "        [4492],\n",
            "        [ 601],\n",
            "        [4872],\n",
            "        [1274],\n",
            "        [1393],\n",
            "        [6284],\n",
            "        [1152],\n",
            "        [4673],\n",
            "        [3519],\n",
            "        [6023]])\n",
            "Evaluation — Loss: 0.0081, Accuracy: 0.0000\n",
            "Epoch 7 — Train Loss: 0.0016, Val Loss: 0.0081, Val Acc: 0.0000\n",
            "Epoch: 7\n",
            "tensor([[6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054]])\n",
            "tensor([[6092],\n",
            "        [1243],\n",
            "        [ 640],\n",
            "        [4789],\n",
            "        [5163],\n",
            "        [6184],\n",
            "        [2038],\n",
            "        [6250],\n",
            "        [5596],\n",
            "        [4641],\n",
            "        [6097],\n",
            "        [6007],\n",
            "        [1009],\n",
            "        [6027],\n",
            "        [4613],\n",
            "        [6023],\n",
            "        [6283],\n",
            "        [6013],\n",
            "        [1363],\n",
            "        [1635],\n",
            "        [5672],\n",
            "        [5997],\n",
            "        [6231],\n",
            "        [6023],\n",
            "        [6286],\n",
            "        [1172],\n",
            "        [ 522],\n",
            "        [6172],\n",
            "        [5289],\n",
            "        [5793],\n",
            "        [4673],\n",
            "        [5930]])\n",
            "tensor([[6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054]])\n",
            "tensor([[6068],\n",
            "        [6274],\n",
            "        [6342],\n",
            "        [4512],\n",
            "        [ 788],\n",
            "        [6227],\n",
            "        [ 623],\n",
            "        [6088],\n",
            "        [5852],\n",
            "        [1747],\n",
            "        [6329],\n",
            "        [3754],\n",
            "        [6349],\n",
            "        [3828],\n",
            "        [6325],\n",
            "        [5672],\n",
            "        [3945],\n",
            "        [2157],\n",
            "        [4353],\n",
            "        [5100],\n",
            "        [6277],\n",
            "        [2396],\n",
            "        [1243],\n",
            "        [ 709],\n",
            "        [ 623],\n",
            "        [4192],\n",
            "        [ 766],\n",
            "        [1147],\n",
            "        [4522],\n",
            "        [6342],\n",
            "        [6027],\n",
            "        [6280]])\n",
            "tensor([[6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054]])\n",
            "tensor([[6328],\n",
            "        [ 539],\n",
            "        [ 672],\n",
            "        [6101],\n",
            "        [4492],\n",
            "        [ 601],\n",
            "        [4872],\n",
            "        [1274],\n",
            "        [1393],\n",
            "        [6284],\n",
            "        [1152],\n",
            "        [4673],\n",
            "        [3519],\n",
            "        [6023]])\n",
            "Evaluation — Loss: 0.0071, Accuracy: 0.0000\n",
            "Epoch 8 — Train Loss: 0.0014, Val Loss: 0.0071, Val Acc: 0.0000\n",
            "Epoch: 8\n",
            "tensor([[6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054]])\n",
            "tensor([[6092],\n",
            "        [1243],\n",
            "        [ 640],\n",
            "        [4789],\n",
            "        [5163],\n",
            "        [6184],\n",
            "        [2038],\n",
            "        [6250],\n",
            "        [5596],\n",
            "        [4641],\n",
            "        [6097],\n",
            "        [6007],\n",
            "        [1009],\n",
            "        [6027],\n",
            "        [4613],\n",
            "        [6023],\n",
            "        [6283],\n",
            "        [6013],\n",
            "        [1363],\n",
            "        [1635],\n",
            "        [5672],\n",
            "        [5997],\n",
            "        [6231],\n",
            "        [6023],\n",
            "        [6286],\n",
            "        [1172],\n",
            "        [ 522],\n",
            "        [6172],\n",
            "        [5289],\n",
            "        [5793],\n",
            "        [4673],\n",
            "        [5930]])\n",
            "tensor([[6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054]])\n",
            "tensor([[6068],\n",
            "        [6274],\n",
            "        [6342],\n",
            "        [4512],\n",
            "        [ 788],\n",
            "        [6227],\n",
            "        [ 623],\n",
            "        [6088],\n",
            "        [5852],\n",
            "        [1747],\n",
            "        [6329],\n",
            "        [3754],\n",
            "        [6349],\n",
            "        [3828],\n",
            "        [6325],\n",
            "        [5672],\n",
            "        [3945],\n",
            "        [2157],\n",
            "        [4353],\n",
            "        [5100],\n",
            "        [6277],\n",
            "        [2396],\n",
            "        [1243],\n",
            "        [ 709],\n",
            "        [ 623],\n",
            "        [4192],\n",
            "        [ 766],\n",
            "        [1147],\n",
            "        [4522],\n",
            "        [6342],\n",
            "        [6027],\n",
            "        [6280]])\n",
            "tensor([[6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054]])\n",
            "tensor([[6328],\n",
            "        [ 539],\n",
            "        [ 672],\n",
            "        [6101],\n",
            "        [4492],\n",
            "        [ 601],\n",
            "        [4872],\n",
            "        [1274],\n",
            "        [1393],\n",
            "        [6284],\n",
            "        [1152],\n",
            "        [4673],\n",
            "        [3519],\n",
            "        [6023]])\n",
            "Evaluation — Loss: 0.0063, Accuracy: 0.0000\n",
            "Epoch 9 — Train Loss: 0.0013, Val Loss: 0.0063, Val Acc: 0.0000\n",
            "Epoch: 9\n",
            "tensor([[6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054]])\n",
            "tensor([[6092],\n",
            "        [1243],\n",
            "        [ 640],\n",
            "        [4789],\n",
            "        [5163],\n",
            "        [6184],\n",
            "        [2038],\n",
            "        [6250],\n",
            "        [5596],\n",
            "        [4641],\n",
            "        [6097],\n",
            "        [6007],\n",
            "        [1009],\n",
            "        [6027],\n",
            "        [4613],\n",
            "        [6023],\n",
            "        [6283],\n",
            "        [6013],\n",
            "        [1363],\n",
            "        [1635],\n",
            "        [5672],\n",
            "        [5997],\n",
            "        [6231],\n",
            "        [6023],\n",
            "        [6286],\n",
            "        [1172],\n",
            "        [ 522],\n",
            "        [6172],\n",
            "        [5289],\n",
            "        [5793],\n",
            "        [4673],\n",
            "        [5930]])\n",
            "tensor([[6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054]])\n",
            "tensor([[6068],\n",
            "        [6274],\n",
            "        [6342],\n",
            "        [4512],\n",
            "        [ 788],\n",
            "        [6227],\n",
            "        [ 623],\n",
            "        [6088],\n",
            "        [5852],\n",
            "        [1747],\n",
            "        [6329],\n",
            "        [3754],\n",
            "        [6349],\n",
            "        [3828],\n",
            "        [6325],\n",
            "        [5672],\n",
            "        [3945],\n",
            "        [2157],\n",
            "        [4353],\n",
            "        [5100],\n",
            "        [6277],\n",
            "        [2396],\n",
            "        [1243],\n",
            "        [ 709],\n",
            "        [ 623],\n",
            "        [4192],\n",
            "        [ 766],\n",
            "        [1147],\n",
            "        [4522],\n",
            "        [6342],\n",
            "        [6027],\n",
            "        [6280]])\n",
            "tensor([[6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054]])\n",
            "tensor([[6328],\n",
            "        [ 539],\n",
            "        [ 672],\n",
            "        [6101],\n",
            "        [4492],\n",
            "        [ 601],\n",
            "        [4872],\n",
            "        [1274],\n",
            "        [1393],\n",
            "        [6284],\n",
            "        [1152],\n",
            "        [4673],\n",
            "        [3519],\n",
            "        [6023]])\n",
            "Evaluation — Loss: 0.0057, Accuracy: 0.0000\n",
            "Epoch 10 — Train Loss: 0.0011, Val Loss: 0.0057, Val Acc: 0.0000\n",
            "Epoch: 10\n",
            "tensor([[6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054]])\n",
            "tensor([[6092],\n",
            "        [1243],\n",
            "        [ 640],\n",
            "        [4789],\n",
            "        [5163],\n",
            "        [6184],\n",
            "        [2038],\n",
            "        [6250],\n",
            "        [5596],\n",
            "        [4641],\n",
            "        [6097],\n",
            "        [6007],\n",
            "        [1009],\n",
            "        [6027],\n",
            "        [4613],\n",
            "        [6023],\n",
            "        [6283],\n",
            "        [6013],\n",
            "        [1363],\n",
            "        [1635],\n",
            "        [5672],\n",
            "        [5997],\n",
            "        [6231],\n",
            "        [6023],\n",
            "        [6286],\n",
            "        [1172],\n",
            "        [ 522],\n",
            "        [6172],\n",
            "        [5289],\n",
            "        [5793],\n",
            "        [4673],\n",
            "        [5930]])\n",
            "tensor([[6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054]])\n",
            "tensor([[6068],\n",
            "        [6274],\n",
            "        [6342],\n",
            "        [4512],\n",
            "        [ 788],\n",
            "        [6227],\n",
            "        [ 623],\n",
            "        [6088],\n",
            "        [5852],\n",
            "        [1747],\n",
            "        [6329],\n",
            "        [3754],\n",
            "        [6349],\n",
            "        [3828],\n",
            "        [6325],\n",
            "        [5672],\n",
            "        [3945],\n",
            "        [2157],\n",
            "        [4353],\n",
            "        [5100],\n",
            "        [6277],\n",
            "        [2396],\n",
            "        [1243],\n",
            "        [ 709],\n",
            "        [ 623],\n",
            "        [4192],\n",
            "        [ 766],\n",
            "        [1147],\n",
            "        [4522],\n",
            "        [6342],\n",
            "        [6027],\n",
            "        [6280]])\n",
            "tensor([[6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054]])\n",
            "tensor([[6328],\n",
            "        [ 539],\n",
            "        [ 672],\n",
            "        [6101],\n",
            "        [4492],\n",
            "        [ 601],\n",
            "        [4872],\n",
            "        [1274],\n",
            "        [1393],\n",
            "        [6284],\n",
            "        [1152],\n",
            "        [4673],\n",
            "        [3519],\n",
            "        [6023]])\n",
            "Evaluation — Loss: 0.0052, Accuracy: 0.0000\n",
            "Epoch 11 — Train Loss: 0.0010, Val Loss: 0.0052, Val Acc: 0.0000\n",
            "Epoch: 11\n",
            "tensor([[6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054]])\n",
            "tensor([[6092],\n",
            "        [1243],\n",
            "        [ 640],\n",
            "        [4789],\n",
            "        [5163],\n",
            "        [6184],\n",
            "        [2038],\n",
            "        [6250],\n",
            "        [5596],\n",
            "        [4641],\n",
            "        [6097],\n",
            "        [6007],\n",
            "        [1009],\n",
            "        [6027],\n",
            "        [4613],\n",
            "        [6023],\n",
            "        [6283],\n",
            "        [6013],\n",
            "        [1363],\n",
            "        [1635],\n",
            "        [5672],\n",
            "        [5997],\n",
            "        [6231],\n",
            "        [6023],\n",
            "        [6286],\n",
            "        [1172],\n",
            "        [ 522],\n",
            "        [6172],\n",
            "        [5289],\n",
            "        [5793],\n",
            "        [4673],\n",
            "        [5930]])\n",
            "tensor([[6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054]])\n",
            "tensor([[6068],\n",
            "        [6274],\n",
            "        [6342],\n",
            "        [4512],\n",
            "        [ 788],\n",
            "        [6227],\n",
            "        [ 623],\n",
            "        [6088],\n",
            "        [5852],\n",
            "        [1747],\n",
            "        [6329],\n",
            "        [3754],\n",
            "        [6349],\n",
            "        [3828],\n",
            "        [6325],\n",
            "        [5672],\n",
            "        [3945],\n",
            "        [2157],\n",
            "        [4353],\n",
            "        [5100],\n",
            "        [6277],\n",
            "        [2396],\n",
            "        [1243],\n",
            "        [ 709],\n",
            "        [ 623],\n",
            "        [4192],\n",
            "        [ 766],\n",
            "        [1147],\n",
            "        [4522],\n",
            "        [6342],\n",
            "        [6027],\n",
            "        [6280]])\n",
            "tensor([[6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054]])\n",
            "tensor([[6328],\n",
            "        [ 539],\n",
            "        [ 672],\n",
            "        [6101],\n",
            "        [4492],\n",
            "        [ 601],\n",
            "        [4872],\n",
            "        [1274],\n",
            "        [1393],\n",
            "        [6284],\n",
            "        [1152],\n",
            "        [4673],\n",
            "        [3519],\n",
            "        [6023]])\n",
            "Evaluation — Loss: 0.0048, Accuracy: 0.0000\n",
            "Epoch 12 — Train Loss: 0.0010, Val Loss: 0.0048, Val Acc: 0.0000\n",
            "Epoch: 12\n",
            "tensor([[6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054]])\n",
            "tensor([[6092],\n",
            "        [1243],\n",
            "        [ 640],\n",
            "        [4789],\n",
            "        [5163],\n",
            "        [6184],\n",
            "        [2038],\n",
            "        [6250],\n",
            "        [5596],\n",
            "        [4641],\n",
            "        [6097],\n",
            "        [6007],\n",
            "        [1009],\n",
            "        [6027],\n",
            "        [4613],\n",
            "        [6023],\n",
            "        [6283],\n",
            "        [6013],\n",
            "        [1363],\n",
            "        [1635],\n",
            "        [5672],\n",
            "        [5997],\n",
            "        [6231],\n",
            "        [6023],\n",
            "        [6286],\n",
            "        [1172],\n",
            "        [ 522],\n",
            "        [6172],\n",
            "        [5289],\n",
            "        [5793],\n",
            "        [4673],\n",
            "        [5930]])\n",
            "tensor([[6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054]])\n",
            "tensor([[6068],\n",
            "        [6274],\n",
            "        [6342],\n",
            "        [4512],\n",
            "        [ 788],\n",
            "        [6227],\n",
            "        [ 623],\n",
            "        [6088],\n",
            "        [5852],\n",
            "        [1747],\n",
            "        [6329],\n",
            "        [3754],\n",
            "        [6349],\n",
            "        [3828],\n",
            "        [6325],\n",
            "        [5672],\n",
            "        [3945],\n",
            "        [2157],\n",
            "        [4353],\n",
            "        [5100],\n",
            "        [6277],\n",
            "        [2396],\n",
            "        [1243],\n",
            "        [ 709],\n",
            "        [ 623],\n",
            "        [4192],\n",
            "        [ 766],\n",
            "        [1147],\n",
            "        [4522],\n",
            "        [6342],\n",
            "        [6027],\n",
            "        [6280]])\n",
            "tensor([[6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054]])\n",
            "tensor([[6328],\n",
            "        [ 539],\n",
            "        [ 672],\n",
            "        [6101],\n",
            "        [4492],\n",
            "        [ 601],\n",
            "        [4872],\n",
            "        [1274],\n",
            "        [1393],\n",
            "        [6284],\n",
            "        [1152],\n",
            "        [4673],\n",
            "        [3519],\n",
            "        [6023]])\n",
            "Evaluation — Loss: 0.0045, Accuracy: 0.0000\n",
            "Epoch 13 — Train Loss: 0.0009, Val Loss: 0.0045, Val Acc: 0.0000\n",
            "Epoch: 13\n",
            "tensor([[6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054]])\n",
            "tensor([[6092],\n",
            "        [1243],\n",
            "        [ 640],\n",
            "        [4789],\n",
            "        [5163],\n",
            "        [6184],\n",
            "        [2038],\n",
            "        [6250],\n",
            "        [5596],\n",
            "        [4641],\n",
            "        [6097],\n",
            "        [6007],\n",
            "        [1009],\n",
            "        [6027],\n",
            "        [4613],\n",
            "        [6023],\n",
            "        [6283],\n",
            "        [6013],\n",
            "        [1363],\n",
            "        [1635],\n",
            "        [5672],\n",
            "        [5997],\n",
            "        [6231],\n",
            "        [6023],\n",
            "        [6286],\n",
            "        [1172],\n",
            "        [ 522],\n",
            "        [6172],\n",
            "        [5289],\n",
            "        [5793],\n",
            "        [4673],\n",
            "        [5930]])\n",
            "tensor([[6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054]])\n",
            "tensor([[6068],\n",
            "        [6274],\n",
            "        [6342],\n",
            "        [4512],\n",
            "        [ 788],\n",
            "        [6227],\n",
            "        [ 623],\n",
            "        [6088],\n",
            "        [5852],\n",
            "        [1747],\n",
            "        [6329],\n",
            "        [3754],\n",
            "        [6349],\n",
            "        [3828],\n",
            "        [6325],\n",
            "        [5672],\n",
            "        [3945],\n",
            "        [2157],\n",
            "        [4353],\n",
            "        [5100],\n",
            "        [6277],\n",
            "        [2396],\n",
            "        [1243],\n",
            "        [ 709],\n",
            "        [ 623],\n",
            "        [4192],\n",
            "        [ 766],\n",
            "        [1147],\n",
            "        [4522],\n",
            "        [6342],\n",
            "        [6027],\n",
            "        [6280]])\n",
            "tensor([[6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054]])\n",
            "tensor([[6328],\n",
            "        [ 539],\n",
            "        [ 672],\n",
            "        [6101],\n",
            "        [4492],\n",
            "        [ 601],\n",
            "        [4872],\n",
            "        [1274],\n",
            "        [1393],\n",
            "        [6284],\n",
            "        [1152],\n",
            "        [4673],\n",
            "        [3519],\n",
            "        [6023]])\n",
            "Evaluation — Loss: 0.0042, Accuracy: 0.0000\n",
            "Epoch 14 — Train Loss: 0.0008, Val Loss: 0.0042, Val Acc: 0.0000\n",
            "Epoch: 14\n",
            "tensor([[6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054]])\n",
            "tensor([[6092],\n",
            "        [1243],\n",
            "        [ 640],\n",
            "        [4789],\n",
            "        [5163],\n",
            "        [6184],\n",
            "        [2038],\n",
            "        [6250],\n",
            "        [5596],\n",
            "        [4641],\n",
            "        [6097],\n",
            "        [6007],\n",
            "        [1009],\n",
            "        [6027],\n",
            "        [4613],\n",
            "        [6023],\n",
            "        [6283],\n",
            "        [6013],\n",
            "        [1363],\n",
            "        [1635],\n",
            "        [5672],\n",
            "        [5997],\n",
            "        [6231],\n",
            "        [6023],\n",
            "        [6286],\n",
            "        [1172],\n",
            "        [ 522],\n",
            "        [6172],\n",
            "        [5289],\n",
            "        [5793],\n",
            "        [4673],\n",
            "        [5930]])\n",
            "tensor([[6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054]])\n",
            "tensor([[6068],\n",
            "        [6274],\n",
            "        [6342],\n",
            "        [4512],\n",
            "        [ 788],\n",
            "        [6227],\n",
            "        [ 623],\n",
            "        [6088],\n",
            "        [5852],\n",
            "        [1747],\n",
            "        [6329],\n",
            "        [3754],\n",
            "        [6349],\n",
            "        [3828],\n",
            "        [6325],\n",
            "        [5672],\n",
            "        [3945],\n",
            "        [2157],\n",
            "        [4353],\n",
            "        [5100],\n",
            "        [6277],\n",
            "        [2396],\n",
            "        [1243],\n",
            "        [ 709],\n",
            "        [ 623],\n",
            "        [4192],\n",
            "        [ 766],\n",
            "        [1147],\n",
            "        [4522],\n",
            "        [6342],\n",
            "        [6027],\n",
            "        [6280]])\n",
            "tensor([[6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054]])\n",
            "tensor([[6328],\n",
            "        [ 539],\n",
            "        [ 672],\n",
            "        [6101],\n",
            "        [4492],\n",
            "        [ 601],\n",
            "        [4872],\n",
            "        [1274],\n",
            "        [1393],\n",
            "        [6284],\n",
            "        [1152],\n",
            "        [4673],\n",
            "        [3519],\n",
            "        [6023]])\n",
            "Evaluation — Loss: 0.0039, Accuracy: 0.0000\n",
            "Epoch 15 — Train Loss: 0.0008, Val Loss: 0.0039, Val Acc: 0.0000\n",
            "Epoch: 15\n",
            "tensor([[6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054]])\n",
            "tensor([[6092],\n",
            "        [1243],\n",
            "        [ 640],\n",
            "        [4789],\n",
            "        [5163],\n",
            "        [6184],\n",
            "        [2038],\n",
            "        [6250],\n",
            "        [5596],\n",
            "        [4641],\n",
            "        [6097],\n",
            "        [6007],\n",
            "        [1009],\n",
            "        [6027],\n",
            "        [4613],\n",
            "        [6023],\n",
            "        [6283],\n",
            "        [6013],\n",
            "        [1363],\n",
            "        [1635],\n",
            "        [5672],\n",
            "        [5997],\n",
            "        [6231],\n",
            "        [6023],\n",
            "        [6286],\n",
            "        [1172],\n",
            "        [ 522],\n",
            "        [6172],\n",
            "        [5289],\n",
            "        [5793],\n",
            "        [4673],\n",
            "        [5930]])\n",
            "tensor([[6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054]])\n",
            "tensor([[6068],\n",
            "        [6274],\n",
            "        [6342],\n",
            "        [4512],\n",
            "        [ 788],\n",
            "        [6227],\n",
            "        [ 623],\n",
            "        [6088],\n",
            "        [5852],\n",
            "        [1747],\n",
            "        [6329],\n",
            "        [3754],\n",
            "        [6349],\n",
            "        [3828],\n",
            "        [6325],\n",
            "        [5672],\n",
            "        [3945],\n",
            "        [2157],\n",
            "        [4353],\n",
            "        [5100],\n",
            "        [6277],\n",
            "        [2396],\n",
            "        [1243],\n",
            "        [ 709],\n",
            "        [ 623],\n",
            "        [4192],\n",
            "        [ 766],\n",
            "        [1147],\n",
            "        [4522],\n",
            "        [6342],\n",
            "        [6027],\n",
            "        [6280]])\n",
            "tensor([[6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054]])\n",
            "tensor([[6328],\n",
            "        [ 539],\n",
            "        [ 672],\n",
            "        [6101],\n",
            "        [4492],\n",
            "        [ 601],\n",
            "        [4872],\n",
            "        [1274],\n",
            "        [1393],\n",
            "        [6284],\n",
            "        [1152],\n",
            "        [4673],\n",
            "        [3519],\n",
            "        [6023]])\n",
            "Evaluation — Loss: 0.0037, Accuracy: 0.0000\n",
            "Epoch 16 — Train Loss: 0.0007, Val Loss: 0.0037, Val Acc: 0.0000\n",
            "Epoch: 16\n",
            "tensor([[6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054]])\n",
            "tensor([[6092],\n",
            "        [1243],\n",
            "        [ 640],\n",
            "        [4789],\n",
            "        [5163],\n",
            "        [6184],\n",
            "        [2038],\n",
            "        [6250],\n",
            "        [5596],\n",
            "        [4641],\n",
            "        [6097],\n",
            "        [6007],\n",
            "        [1009],\n",
            "        [6027],\n",
            "        [4613],\n",
            "        [6023],\n",
            "        [6283],\n",
            "        [6013],\n",
            "        [1363],\n",
            "        [1635],\n",
            "        [5672],\n",
            "        [5997],\n",
            "        [6231],\n",
            "        [6023],\n",
            "        [6286],\n",
            "        [1172],\n",
            "        [ 522],\n",
            "        [6172],\n",
            "        [5289],\n",
            "        [5793],\n",
            "        [4673],\n",
            "        [5930]])\n",
            "tensor([[6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054]])\n",
            "tensor([[6068],\n",
            "        [6274],\n",
            "        [6342],\n",
            "        [4512],\n",
            "        [ 788],\n",
            "        [6227],\n",
            "        [ 623],\n",
            "        [6088],\n",
            "        [5852],\n",
            "        [1747],\n",
            "        [6329],\n",
            "        [3754],\n",
            "        [6349],\n",
            "        [3828],\n",
            "        [6325],\n",
            "        [5672],\n",
            "        [3945],\n",
            "        [2157],\n",
            "        [4353],\n",
            "        [5100],\n",
            "        [6277],\n",
            "        [2396],\n",
            "        [1243],\n",
            "        [ 709],\n",
            "        [ 623],\n",
            "        [4192],\n",
            "        [ 766],\n",
            "        [1147],\n",
            "        [4522],\n",
            "        [6342],\n",
            "        [6027],\n",
            "        [6280]])\n",
            "tensor([[6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054]])\n",
            "tensor([[6328],\n",
            "        [ 539],\n",
            "        [ 672],\n",
            "        [6101],\n",
            "        [4492],\n",
            "        [ 601],\n",
            "        [4872],\n",
            "        [1274],\n",
            "        [1393],\n",
            "        [6284],\n",
            "        [1152],\n",
            "        [4673],\n",
            "        [3519],\n",
            "        [6023]])\n",
            "Evaluation — Loss: 0.0035, Accuracy: 0.0000\n",
            "Epoch 17 — Train Loss: 0.0007, Val Loss: 0.0035, Val Acc: 0.0000\n",
            "Epoch: 17\n",
            "tensor([[6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054]])\n",
            "tensor([[6092],\n",
            "        [1243],\n",
            "        [ 640],\n",
            "        [4789],\n",
            "        [5163],\n",
            "        [6184],\n",
            "        [2038],\n",
            "        [6250],\n",
            "        [5596],\n",
            "        [4641],\n",
            "        [6097],\n",
            "        [6007],\n",
            "        [1009],\n",
            "        [6027],\n",
            "        [4613],\n",
            "        [6023],\n",
            "        [6283],\n",
            "        [6013],\n",
            "        [1363],\n",
            "        [1635],\n",
            "        [5672],\n",
            "        [5997],\n",
            "        [6231],\n",
            "        [6023],\n",
            "        [6286],\n",
            "        [1172],\n",
            "        [ 522],\n",
            "        [6172],\n",
            "        [5289],\n",
            "        [5793],\n",
            "        [4673],\n",
            "        [5930]])\n",
            "tensor([[6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054]])\n",
            "tensor([[6068],\n",
            "        [6274],\n",
            "        [6342],\n",
            "        [4512],\n",
            "        [ 788],\n",
            "        [6227],\n",
            "        [ 623],\n",
            "        [6088],\n",
            "        [5852],\n",
            "        [1747],\n",
            "        [6329],\n",
            "        [3754],\n",
            "        [6349],\n",
            "        [3828],\n",
            "        [6325],\n",
            "        [5672],\n",
            "        [3945],\n",
            "        [2157],\n",
            "        [4353],\n",
            "        [5100],\n",
            "        [6277],\n",
            "        [2396],\n",
            "        [1243],\n",
            "        [ 709],\n",
            "        [ 623],\n",
            "        [4192],\n",
            "        [ 766],\n",
            "        [1147],\n",
            "        [4522],\n",
            "        [6342],\n",
            "        [6027],\n",
            "        [6280]])\n",
            "tensor([[6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054]])\n",
            "tensor([[6328],\n",
            "        [ 539],\n",
            "        [ 672],\n",
            "        [6101],\n",
            "        [4492],\n",
            "        [ 601],\n",
            "        [4872],\n",
            "        [1274],\n",
            "        [1393],\n",
            "        [6284],\n",
            "        [1152],\n",
            "        [4673],\n",
            "        [3519],\n",
            "        [6023]])\n",
            "Evaluation — Loss: 0.0034, Accuracy: 0.0000\n",
            "Epoch 18 — Train Loss: 0.0007, Val Loss: 0.0034, Val Acc: 0.0000\n",
            "Epoch: 18\n",
            "tensor([[6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054]])\n",
            "tensor([[6092],\n",
            "        [1243],\n",
            "        [ 640],\n",
            "        [4789],\n",
            "        [5163],\n",
            "        [6184],\n",
            "        [2038],\n",
            "        [6250],\n",
            "        [5596],\n",
            "        [4641],\n",
            "        [6097],\n",
            "        [6007],\n",
            "        [1009],\n",
            "        [6027],\n",
            "        [4613],\n",
            "        [6023],\n",
            "        [6283],\n",
            "        [6013],\n",
            "        [1363],\n",
            "        [1635],\n",
            "        [5672],\n",
            "        [5997],\n",
            "        [6231],\n",
            "        [6023],\n",
            "        [6286],\n",
            "        [1172],\n",
            "        [ 522],\n",
            "        [6172],\n",
            "        [5289],\n",
            "        [5793],\n",
            "        [4673],\n",
            "        [5930]])\n",
            "tensor([[6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054]])\n",
            "tensor([[6068],\n",
            "        [6274],\n",
            "        [6342],\n",
            "        [4512],\n",
            "        [ 788],\n",
            "        [6227],\n",
            "        [ 623],\n",
            "        [6088],\n",
            "        [5852],\n",
            "        [1747],\n",
            "        [6329],\n",
            "        [3754],\n",
            "        [6349],\n",
            "        [3828],\n",
            "        [6325],\n",
            "        [5672],\n",
            "        [3945],\n",
            "        [2157],\n",
            "        [4353],\n",
            "        [5100],\n",
            "        [6277],\n",
            "        [2396],\n",
            "        [1243],\n",
            "        [ 709],\n",
            "        [ 623],\n",
            "        [4192],\n",
            "        [ 766],\n",
            "        [1147],\n",
            "        [4522],\n",
            "        [6342],\n",
            "        [6027],\n",
            "        [6280]])\n",
            "tensor([[6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054]])\n",
            "tensor([[6328],\n",
            "        [ 539],\n",
            "        [ 672],\n",
            "        [6101],\n",
            "        [4492],\n",
            "        [ 601],\n",
            "        [4872],\n",
            "        [1274],\n",
            "        [1393],\n",
            "        [6284],\n",
            "        [1152],\n",
            "        [4673],\n",
            "        [3519],\n",
            "        [6023]])\n",
            "Evaluation — Loss: 0.0032, Accuracy: 0.0000\n",
            "Epoch 19 — Train Loss: 0.0006, Val Loss: 0.0032, Val Acc: 0.0000\n",
            "Epoch: 19\n",
            "tensor([[6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054]])\n",
            "tensor([[6092],\n",
            "        [1243],\n",
            "        [ 640],\n",
            "        [4789],\n",
            "        [5163],\n",
            "        [6184],\n",
            "        [2038],\n",
            "        [6250],\n",
            "        [5596],\n",
            "        [4641],\n",
            "        [6097],\n",
            "        [6007],\n",
            "        [1009],\n",
            "        [6027],\n",
            "        [4613],\n",
            "        [6023],\n",
            "        [6283],\n",
            "        [6013],\n",
            "        [1363],\n",
            "        [1635],\n",
            "        [5672],\n",
            "        [5997],\n",
            "        [6231],\n",
            "        [6023],\n",
            "        [6286],\n",
            "        [1172],\n",
            "        [ 522],\n",
            "        [6172],\n",
            "        [5289],\n",
            "        [5793],\n",
            "        [4673],\n",
            "        [5930]])\n",
            "tensor([[6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054]])\n",
            "tensor([[6068],\n",
            "        [6274],\n",
            "        [6342],\n",
            "        [4512],\n",
            "        [ 788],\n",
            "        [6227],\n",
            "        [ 623],\n",
            "        [6088],\n",
            "        [5852],\n",
            "        [1747],\n",
            "        [6329],\n",
            "        [3754],\n",
            "        [6349],\n",
            "        [3828],\n",
            "        [6325],\n",
            "        [5672],\n",
            "        [3945],\n",
            "        [2157],\n",
            "        [4353],\n",
            "        [5100],\n",
            "        [6277],\n",
            "        [2396],\n",
            "        [1243],\n",
            "        [ 709],\n",
            "        [ 623],\n",
            "        [4192],\n",
            "        [ 766],\n",
            "        [1147],\n",
            "        [4522],\n",
            "        [6342],\n",
            "        [6027],\n",
            "        [6280]])\n",
            "tensor([[6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054],\n",
            "        [6054]])\n",
            "tensor([[6328],\n",
            "        [ 539],\n",
            "        [ 672],\n",
            "        [6101],\n",
            "        [4492],\n",
            "        [ 601],\n",
            "        [4872],\n",
            "        [1274],\n",
            "        [1393],\n",
            "        [6284],\n",
            "        [1152],\n",
            "        [4673],\n",
            "        [3519],\n",
            "        [6023]])\n",
            "Evaluation — Loss: 0.0031, Accuracy: 0.0000\n",
            "Epoch 20 — Train Loss: 0.0006, Val Loss: 0.0031, Val Acc: 0.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TODO For Future\n",
        "\n",
        "- Explore Pytorch's Embedding bag class for Recommender Systems.\n",
        "\n",
        "# TODO For Debug\n",
        "\n",
        "- Check embedding layer after a forward pass\n",
        "- Check Metadata layer\n",
        "- Check variabilitiy in y_train"
      ],
      "metadata": {
        "id": "iMUTldv6YSW3"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E6t7dIN9FeNc"
      },
      "source": [
        "# Testing\n",
        "\n",
        "- Hold out a test\n",
        "- Find a better Resource features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TcxdH5zlFeNc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZ4n8rpD7l7d"
      },
      "source": [
        "### Compiling LSTM Architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eevtNKUp7l7d"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "te = TransactionEncoder()\n",
        "padded_resource_sets = pad_resource_sets(resources_sets)\n",
        "\n",
        "# TODO this seems impossible\n",
        "\n",
        "# Todo for any itemset (eg. A, B, C) find all the students that have this itemset and check their labels\n",
        "\n",
        "padded_sequence, labels = get_sets_labels(padded_resource_sets)\n",
        "\n",
        "te.fit(padded_sequence)\n",
        "padded_sequence = te.transform(padded_sequence)\n",
        "\n",
        "unique_ids = np.unique(padded_resource_sets.flatten())\n",
        "\n",
        "# print(unique_ids.shape)\n",
        "\n",
        "id_to_index = {id: index for index, id in enumerate(unique_ids)}\n",
        "index_to_id = {index: id for index, id in enumerate(unique_ids)}\n",
        "\n",
        "\n",
        "vectorized_map = np.vectorize(id_to_index.get)\n",
        "tokenized_resource_sequence = vectorized_map(padded_resource_sets)\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "labels = label_encoder.fit_transform(labels)\n",
        "labels = to_categorical(labels, num_classes=np.unique(labels).shape[0])\n",
        "\n",
        "\n",
        "# drop last element from every list in tokenized_resource_sequence\n",
        "tokenized_resource_sequence = np.delete(tokenized_resource_sequence, -1, axis=1)\n",
        "\n",
        "print(tokenized_resource_sequence)\n",
        "# One-hot encode the labels\n",
        "\n",
        "\n",
        "vocab_size = np.unique(padded_resource_sets.flatten()).shape[0]\n",
        "embedding_dim = 64\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Embedding(input_dim=vocab_size + 1, output_dim=embedding_dim))\n",
        "model.add(LSTM(64, return_sequences=True))\n",
        "model.add(LSTM(64))\n",
        "model.add(Dense(labels.shape[1], activation='softmax'))\n",
        "model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n",
        "print(tokenized_resource_sequence.shape)\n",
        "print(labels.shape)\n",
        "model.fit(tokenized_resource_sequence, labels, epochs=10, batch_size=32, validation_split=0.4)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6E6vg2oT7l7d"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}